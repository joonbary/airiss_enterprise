# integration_test_suite.py
"""
AIRISS v4.0 ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸
í¸í–¥ íƒì§€ + ì˜ˆì¸¡ ë¶„ì„ + ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ í†µí•© ê²€ì¦
"""

import asyncio
import pandas as pd
import numpy as np
from datetime import datetime
import json
import websockets
import requests
import logging
from typing import Dict, List
import os
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.bias_detection.bias_detector import BiasDetector
from app.services.predictive_analytics.performance_predictor import PerformancePredictor
from app.services.hybrid_analyzer import HybridAnalyzer

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AIRISSIntegrationTest:
    """AIRISS v4.0 í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸"""
    
    def __init__(self):
        self.base_url = "http://localhost:8002"
        self.ws_url = "ws://localhost:8002/ws/test_client"
        self.test_results = {
            "timestamp": datetime.now().isoformat(),
            "tests": {},
            "summary": {
                "total": 0,
                "passed": 0,
                "failed": 0
            }
        }
        
    async def run_all_tests(self):
        """ëª¨ë“  í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("ğŸš€ AIRISS v4.0 í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # 1. ì„œë²„ ìƒíƒœ í™•ì¸
        await self.test_server_health()
        
        # 2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        test_data = self.generate_test_data()
        
        # 3. ê¸°ë³¸ ë¶„ì„ í…ŒìŠ¤íŠ¸
        await self.test_basic_analysis(test_data)
        
        # 4. í¸í–¥ íƒì§€ í…ŒìŠ¤íŠ¸
        await self.test_bias_detection(test_data)
        
        # 5. ì˜ˆì¸¡ ë¶„ì„ í…ŒìŠ¤íŠ¸
        await self.test_predictive_analytics(test_data)
        
        # 6. WebSocket ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸
        await self.test_websocket_realtime()
        
        # 7. ì „ì²´ í”Œë¡œìš° í†µí•© í…ŒìŠ¤íŠ¸
        await self.test_end_to_end_flow()
        
        # 8. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
        await self.test_performance_benchmark()
        
        # 9. API ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸
        await self.test_api_response_times()
        
        # 10. ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        await self.test_error_handling()
        
        # ê²°ê³¼ ìš”ì•½
        self.generate_test_report()
        
    async def test_server_health(self):
        """ì„œë²„ ìƒíƒœ í™•ì¸"""
        test_name = "server_health"
        try:
            response = requests.get(f"{self.base_url}/health")
            assert response.status_code == 200
            self.log_test_result(test_name, True, "ì„œë²„ ì •ìƒ ì‘ë™")
        except Exception as e:
            self.log_test_result(test_name, False, str(e))
    
    def generate_test_data(self) -> pd.DataFrame:
        """í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„±"""
        np.random.seed(42)
        n_employees = 200
        
        # í¸í–¥ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì˜ë„ì  ë°ì´í„° ìƒì„±
        genders = np.random.choice(['ë‚¨ì„±', 'ì—¬ì„±'], n_employees, p=[0.6, 0.4])
        ages = np.random.choice(['20ëŒ€', '30ëŒ€', '40ëŒ€', '50ëŒ€'], n_employees)
        departments = np.random.choice(['ì˜ì—…', 'ê°œë°œ', 'HR', 'ì¬ë¬´'], n_employees)
        
        # ì˜ë„ì  í¸í–¥ ì£¼ì… (ì—¬ì„±ì˜ ì ìˆ˜ë¥¼ ë‚®ê²Œ)
        base_scores = np.random.normal(75, 10, n_employees)
        gender_bias = np.where(genders == 'ì—¬ì„±', -5, 0)
        
        data = pd.DataFrame({
            'ì§ì›ID': [f'EMP{str(i).zfill(4)}' for i in range(n_employees)],
            'ì´ë¦„': [f'ì§ì›{i}' for i in range(n_employees)],
            'ì„±ë³„': genders,
            'ì—°ë ¹ëŒ€': ages,
            'ë¶€ì„œ': departments,
            'KPI_ë‹¬ì„±ë¥ ': base_scores + gender_bias + np.random.normal(0, 5, n_employees),
            'í”„ë¡œì íŠ¸_ì„±ê³¼': base_scores + np.random.normal(0, 8, n_employees),
            'í‰ê°€_í”¼ë“œë°±': self.generate_feedback_texts(n_employees),
            'ì—…ë¬´ì¼ì§€': self.generate_work_logs(n_employees)
        })
        
        return data
    
    def generate_feedback_texts(self, n: int) -> List[str]:
        """í‰ê°€ í”¼ë“œë°± í…ìŠ¤íŠ¸ ìƒì„±"""
        positive_keywords = [
            "ìš°ìˆ˜í•œ ì„±ê³¼", "íŒ€ì›Œí¬ ë›°ì–´ë‚¨", "ë¦¬ë”ì‹­ ë°œíœ˜", "í˜ì‹ ì  ì‚¬ê³ ",
            "ì±…ì„ê° ìˆìŒ", "ì„±ì‹¤í•¨", "ì°½ì˜ì ", "í˜‘ì—… ëŠ¥ë ¥ ìš°ìˆ˜"
        ]
        negative_keywords = [
            "ê°œì„  í•„ìš”", "ì†Œí†µ ë¶€ì¡±", "ì§€ê° ì¦ìŒ", "ì§‘ì¤‘ë ¥ ì €í•˜",
            "ëª©í‘œ ë¯¸ë‹¬ì„±", "í˜‘ì—… ì–´ë ¤ì›€", "ë™ê¸°ë¶€ì—¬ í•„ìš”"
        ]
        
        feedbacks = []
        for i in range(n):
            if np.random.random() > 0.3:  # 70% ê¸ì •ì 
                keywords = np.random.choice(positive_keywords, 3)
            else:
                keywords = np.random.choice(negative_keywords, 2)
            feedbacks.append(" ".join(keywords))
        
        return feedbacks
    
    def generate_work_logs(self, n: int) -> List[str]:
        """ì—…ë¬´ì¼ì§€ í…ìŠ¤íŠ¸ ìƒì„±"""
        activities = [
            "í”„ë¡œì íŠ¸ ì™„ë£Œ", "ê³ ê° ë¯¸íŒ… ì„±ê³µ", "ë³´ê³ ì„œ ì‘ì„±",
            "íŒ€ íšŒì˜ ì£¼ë„", "ë¬¸ì œ í•´ê²°", "ì‹ ê·œ ì•„ì´ë””ì–´ ì œì•ˆ",
            "êµìœ¡ ì°¸ì—¬", "ë©˜í† ë§ ì‹¤ì‹œ"
        ]
        
        logs = []
        for i in range(n):
            selected = np.random.choice(activities, 3)
            logs.append(", ".join(selected))
        
        return logs
    
    async def test_basic_analysis(self, test_data: pd.DataFrame):
        """ê¸°ë³¸ ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        test_name = "basic_analysis"
        try:
            analyzer = HybridAnalyzer()
            
            # ìƒ˜í”Œ ë°ì´í„°ë¡œ ë¶„ì„
            sample = test_data.head(10)
            results = []
            
            for _, row in sample.iterrows():
                result = analyzer.analyze_employee(
                    employee_data=row.to_dict(),
                    text_columns=['í‰ê°€_í”¼ë“œë°±', 'ì—…ë¬´ì¼ì§€'],
                    quant_columns=['KPI_ë‹¬ì„±ë¥ ', 'í”„ë¡œì íŠ¸_ì„±ê³¼']
                )
                results.append(result)
            
            # ê²€ì¦
            assert len(results) == 10
            assert all('hybrid_score' in r for r in results)
            assert all(0 <= r['hybrid_score'] <= 100 for r in results)
            
            self.log_test_result(test_name, True, "ê¸°ë³¸ ë¶„ì„ ì •ìƒ ì‘ë™")
            
        except Exception as e:
            self.log_test_result(test_name, False, str(e))
    
    async def test_bias_detection(self, test_data: pd.DataFrame):
        """í¸í–¥ íƒì§€ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        test_name = "bias_detection"
        try:
            # ë¶„ì„ ê²°ê³¼ì— ì ìˆ˜ ì¶”ê°€
            test_data['hybrid_score'] = test_data['KPI_ë‹¬ì„±ë¥ ']
            
            detector = BiasDetector()
            bias_report = detector.detect_bias(test_data)
            
            # ì˜ë„ì ìœ¼ë¡œ ì£¼ì…í•œ ì„±ë³„ í¸í–¥ì´ íƒì§€ë˜ëŠ”ì§€ í™•ì¸
            assert bias_report['summary']['bias_detected'] == True
            assert 'ì„±ë³„' in bias_report['detailed_analysis']
            assert bias_report['detailed_analysis']['ì„±ë³„']['bias_detected'] == True
            
            # HTML ë³´ê³ ì„œ ìƒì„± í…ŒìŠ¤íŠ¸
            html_report = detector.generate_fairness_report(test_data, 'html')
            assert '<h2>' in html_report
            
            self.log_test_result(test_name, True, "í¸í–¥ íƒì§€ ì •ìƒ ì‘ë™")
            
        except Exception as e:
            self.log_test_result(test_name, False, str(e))
    
    async def test_predictive_analytics(self, test_data: pd.DataFrame):
        """ì˜ˆì¸¡ ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        test_name = "predictive_analytics"
        try:
            # ê³¼ê±° ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜
            historical_data = []
            for _, employee in test_data.iterrows():
                for month in range(6):
                    record = employee.to_dict()
                    record['month'] = month
                    record['performance_score'] = np.random.normal(75, 10)
                    historical_data.append(record)
            
            historical_df = pd.DataFrame(historical_data)
            
            # ì˜ˆì¸¡ ëª¨ë¸ í…ŒìŠ¤íŠ¸ (ê°„ë‹¨í•œ êµ¬í˜„)
            from sklearn.linear_model import LinearRegression
            
            # ê° ì§ì›ë³„ íŠ¸ë Œë“œ ì˜ˆì¸¡
            predictions = {}
            for emp_id in test_data['ì§ì›ID'].unique()[:5]:  # 5ëª…ë§Œ í…ŒìŠ¤íŠ¸
                emp_data = historical_df[historical_df['ì§ì›ID'] == emp_id]
                if len(emp_data) > 1:
                    X = emp_data['month'].values.reshape(-1, 1)
                    y = emp_data['performance_score'].values
                    
                    model = LinearRegression()
                    model.fit(X, y)
                    
                    # 6ê°œì›” í›„ ì˜ˆì¸¡
                    future_score = model.predict([[11]])[0]
                    predictions[emp_id] = {
                        'current_score': y[-1],
                        'predicted_score': future_score,
                        'trend': 'improving' if future_score > y[-1] else 'declining'
                    }
            
            assert len(predictions) > 0
            self.log_test_result(test_name, True, f"ì˜ˆì¸¡ ë¶„ì„ ì™„ë£Œ: {len(predictions)}ëª…")
            
        except Exception as e:
            self.log_test_result(test_name, False, str(e))
    
    async def test_websocket_realtime(self):
        """WebSocket ì‹¤ì‹œê°„ í†µì‹  í…ŒìŠ¤íŠ¸"""
        test_name = "websocket_realtime"
        try:
            async with websockets.connect(self.ws_url) as websocket:
                # ì—°ê²° ë©”ì‹œì§€
                await websocket.send(json.dumps({
                    "type": "connect",
                    "client_id": "test_client"
                }))
                
                # ì‘ë‹µ ëŒ€ê¸°
                response = await asyncio.wait_for(
                    websocket.recv(), 
                    timeout=5.0
                )
                
                data = json.loads(response)
                assert data.get('status') == 'connected'
                
                # ë¶„ì„ ì§„í–‰ë¥  ì‹œë®¬ë ˆì´ì…˜
                await websocket.send(json.dumps({
                    "type": "analysis_progress",
                    "progress": 50,
                    "message": "ë¶„ì„ ì¤‘..."
                }))
                
                self.log_test_result(test_name, True, "WebSocket í†µì‹  ì •ìƒ")
                
        except Exception as e:
            self.log_test_result(test_name, False, str(e))
    
    async def test_end_to_end_flow(self):
        """ì „ì²´ í”Œë¡œìš° í†µí•© í…ŒìŠ¤íŠ¸"""
        test_name = "end_to_end_flow"
        try:
            # 1. íŒŒì¼ ì—…ë¡œë“œ ì‹œë®¬ë ˆì´ì…˜
            test_file_path = "test_data.csv"
            test_data = self.generate_test_data()
            test_data.to_csv(test_file_path, index=False)
            
            # 2. ì—…ë¡œë“œ API í˜¸ì¶œ
            with open(test_file_path, 'rb') as f:
                files = {'file': ('test_data.csv', f, 'text/csv')}
                response = requests.post(
                    f"{self.base_url}/api/v1/upload",
                    files=files
                )
            
            if response.status_code == 200:
                upload_result = response.json()
                
                # 3. ë¶„ì„ ì‹œì‘
                analysis_response = requests.post(
                    f"{self.base_url}/api/v1/analyze",
                    json={
                        "file_id": upload_result.get('file_id'),
                        "text_columns": ['í‰ê°€_í”¼ë“œë°±', 'ì—…ë¬´ì¼ì§€'],
                        "quant_columns": ['KPI_ë‹¬ì„±ë¥ ', 'í”„ë¡œì íŠ¸_ì„±ê³¼'],
                        "include_bias_check": True,
                        "include_predictions": True
                    }
                )
                
                if analysis_response.status_code == 200:
                    self.log_test_result(test_name, True, "ì „ì²´ í”Œë¡œìš° ì •ìƒ ì‘ë™")
                else:
                    self.log_test_result(test_name, False, f"ë¶„ì„ API ì˜¤ë¥˜: {analysis_response.status_code}")
            else:
                self.log_test_result(test_name, False, f"ì—…ë¡œë“œ API ì˜¤ë¥˜: {response.status_code}")
            
            # ì •ë¦¬
            if os.path.exists(test_file_path):
                os.remove(test_file_path)
                
        except Exception as e:
            self.log_test_result(test_name, False, str(e))
    
    async def test_performance_benchmark(self):
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸"""
        test_name = "performance_benchmark"
        try:
            import time
            
            # ë‹¤ì–‘í•œ í¬ê¸°ì˜ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸
            sizes = [100, 500, 1000]
            results = {}
            
            for size in sizes:
                test_data = self.generate_test_data()
                test_data = pd.concat([test_data] * (size // 200), ignore_index=True)
                
                start_time = time.time()
                
                # ë¶„ì„ ì‹¤í–‰
                analyzer = HybridAnalyzer()
                for _, row in test_data.head(10).iterrows():
                    analyzer.analyze_employee(
                        employee_data=row.to_dict(),
                        text_columns=['í‰ê°€_í”¼ë“œë°±', 'ì—…ë¬´ì¼ì§€'],
                        quant_columns=['KPI_ë‹¬ì„±ë¥ ', 'í”„ë¡œì íŠ¸_ì„±ê³¼']
                    )
                
                elapsed = time.time() - start_time
                results[size] = elapsed
                
                logger.info(f"  {size}ëª… ë°ì´í„° ì²˜ë¦¬ ì‹œê°„: {elapsed:.2f}ì´ˆ")
            
            # ì„±ëŠ¥ ê¸°ì¤€: 1000ëª… ì²˜ë¦¬ì— 10ì´ˆ ì´ë‚´
            assert results[1000] < 10.0
            
            self.log_test_result(test_name, True, f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í†µê³¼: {results}")
            
        except Exception as e:
            self.log_test_result(test_name, False, str(e))
    
    async def test_api_response_times(self):
        """API ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸"""
        test_name = "api_response_times"
        try:
            import time
            
            endpoints = [
                ("/", "GET"),
                ("/health", "GET"),
                ("/api/v1/analysis/sample", "GET"),
            ]
            
            response_times = {}
            
            for endpoint, method in endpoints:
                start = time.time()
                
                if method == "GET":
                    response = requests.get(f"{self.base_url}{endpoint}")
                else:
                    response = requests.post(f"{self.base_url}{endpoint}")
                
                elapsed = (time.time() - start) * 1000  # ms
                response_times[endpoint] = elapsed
                
                # ì‘ë‹µ ì‹œê°„ ê¸°ì¤€: 500ms ì´ë‚´
                assert elapsed < 500
                logger.info(f"  {endpoint}: {elapsed:.2f}ms")
            
            self.log_test_result(test_name, True, f"API ì‘ë‹µ ì‹œê°„ ì •ìƒ: {response_times}")
            
        except Exception as e:
            self.log_test_result(test_name, False, str(e))
    
    async def test_error_handling(self):
        """ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        test_name = "error_handling"
        try:
            # 1. ì˜ëª»ëœ íŒŒì¼ í˜•ì‹
            response = requests.post(
                f"{self.base_url}/api/v1/upload",
                files={'file': ('test.txt', b'invalid content', 'text/plain')}
            )
            assert response.status_code == 400
            
            # 2. í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½
            bad_data = pd.DataFrame({'col1': [1, 2, 3]})
            bad_data.to_csv('bad_data.csv', index=False)
            
            with open('bad_data.csv', 'rb') as f:
                response = requests.post(
                    f"{self.base_url}/api/v1/upload",
                    files={'file': ('bad_data.csv', f, 'text/csv')}
                )
            
            # 3. ì˜ëª»ëœ ë¶„ì„ ìš”ì²­
            response = requests.post(
                f"{self.base_url}/api/v1/analyze",
                json={"invalid": "request"}
            )
            assert response.status_code in [400, 422]
            
            # ì •ë¦¬
            if os.path.exists('bad_data.csv'):
                os.remove('bad_data.csv')
            
            self.log_test_result(test_name, True, "ì—ëŸ¬ ì²˜ë¦¬ ì •ìƒ ì‘ë™")
            
        except Exception as e:
            self.log_test_result(test_name, False, str(e))
    
    def log_test_result(self, test_name: str, success: bool, message: str):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê¸°ë¡"""
        self.test_results['tests'][test_name] = {
            'success': success,
            'message': message,
            'timestamp': datetime.now().isoformat()
        }
        
        self.test_results['summary']['total'] += 1
        if success:
            self.test_results['summary']['passed'] += 1
            logger.info(f"âœ… {test_name}: {message}")
        else:
            self.test_results['summary']['failed'] += 1
            logger.error(f"âŒ {test_name}: {message}")
    
    def generate_test_report(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
        summary = self.test_results['summary']
        success_rate = (summary['passed'] / summary['total'] * 100) if summary['total'] > 0 else 0
        
        report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           AIRISS v4.0 í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ì‹¤í–‰ ì‹œê°„: {self.test_results['timestamp']}
â•‘ 
â•‘ ğŸ“Š ì „ì²´ ê²°ê³¼:
â•‘   - ì´ í…ŒìŠ¤íŠ¸: {summary['total']}ê°œ
â•‘   - ì„±ê³µ: {summary['passed']}ê°œ
â•‘   - ì‹¤íŒ¨: {summary['failed']}ê°œ
â•‘   - ì„±ê³µë¥ : {success_rate:.1f}%
â•‘
â•‘ ğŸ“‹ ì„¸ë¶€ ê²°ê³¼:
"""
        
        for test_name, result in self.test_results['tests'].items():
            status = "âœ…" if result['success'] else "âŒ"
            report += f"â•‘   {status} {test_name}: {result['message']}\n"
        
        report += """â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        
        logger.info(report)
        
        # JSON íŒŒì¼ë¡œë„ ì €ì¥
        with open('test_results.json', 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2)
        
        logger.info("ğŸ“„ ìƒì„¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ test_results.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    tester = AIRISSIntegrationTest()
    await tester.run_all_tests()

if __name__ == "__main__":
    asyncio.run(main())