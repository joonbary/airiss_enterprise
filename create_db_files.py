# create_db_files.py
import os

def create_db_files():
    """ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ íŒŒì¼ë“¤ ìƒì„±"""
    
    # 1. app/db/base.py - ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
    db_base_content = '''"""
ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ì„¸ì…˜ ê´€ë¦¬
"""
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from sqlalchemy.orm import declarative_base
from typing import AsyncGenerator
import logging

logger = logging.getLogger(__name__)

# Base í´ë˜ìŠ¤ ìƒì„±
Base = declarative_base()

# ì „ì—­ ë³€ìˆ˜
engine = None
AsyncSessionLocal = None

async def init_db():
    """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
    global engine, AsyncSessionLocal
    
    try:
        from app.core.config.settings import settings
        
        # ë¹„ë™ê¸° ì—”ì§„ ìƒì„±
        engine = create_async_engine(
            settings.DATABASE_URL,
            echo=settings.DEBUG,
            future=True
        )
        
        # ì„¸ì…˜ íŒ©í† ë¦¬ ìƒì„±
        AsyncSessionLocal = async_sessionmaker(
            engine,
            class_=AsyncSession,
            expire_on_commit=False
        )
        
        logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
        
        # í…Œì´ë¸” ìƒì„± (ê°œë°œ í™˜ê²½ì—ì„œë§Œ)
        if settings.DEBUG:
            async with engine.begin() as conn:
                await conn.run_sync(Base.metadata.create_all)
                logger.info("ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
                
    except Exception as e:
        logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        raise

async def get_db() -> AsyncGenerator[AsyncSession, None]:
    """ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ì˜ì¡´ì„±"""
    async with AsyncSessionLocal() as session:
        try:
            yield session
        finally:
            await session.close()
'''
    
    # 2. app/models/models.py - SQLAlchemy ëª¨ë¸
    models_content = '''"""
AIRISS v4.0 ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸
"""
from sqlalchemy import Column, String, Float, Integer, DateTime, JSON, ForeignKey, Text, Enum, Boolean
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.orm import relationship
import uuid
from datetime import datetime
import enum

from app.db.base import Base

class JobStatus(str, enum.Enum):
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"

class AnalysisMode(str, enum.Enum):
    TEXT = "text"
    QUANTITATIVE = "quantitative"
    HYBRID = "hybrid"

class AnalysisJob(Base):
    __tablename__ = "analysis_jobs"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    filename = Column(String(255), nullable=False)
    status = Column(Enum(JobStatus), default=JobStatus.PENDING)
    
    # ë ˆì½”ë“œ ì •ë³´
    total_records = Column(Integer, default=0)
    processed_records = Column(Integer, default=0)
    failed_records = Column(Integer, default=0)
    
    # ë¶„ì„ ì„¤ì •
    analysis_mode = Column(Enum(AnalysisMode), default=AnalysisMode.HYBRID)
    sample_size = Column(Integer)
    enable_ai_feedback = Column(Boolean, default=False)
    
    # ì‹œê°„ ì •ë³´
    created_at = Column(DateTime, default=datetime.utcnow)
    started_at = Column(DateTime)
    completed_at = Column(DateTime)
    
    # ë©”íƒ€ë°ì´í„°
    created_by = Column(String(100))
    metadata = Column(JSON)
    error_message = Column(Text)
    
    # í‰ê·  ì ìˆ˜
    average_score = Column(Float)
    
    # ê´€ê³„
    scores = relationship("EmployeeScore", back_populates="job", cascade="all, delete-orphan")
    file_info = relationship("FileUpload", back_populates="job", uselist=False)

class EmployeeScore(Base):
    __tablename__ = "employee_scores"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    job_id = Column(UUID(as_uuid=True), ForeignKey("analysis_jobs.id", ondelete="CASCADE"))
    
    # ì§ì› ì •ë³´
    employee_uid = Column(String(100), nullable=False, index=True)
    
    # ì¢…í•© ì ìˆ˜
    hybrid_score = Column(Float, nullable=False)
    text_score = Column(Float)
    quantitative_score = Column(Float)
    confidence_score = Column(Float)
    
    # ë“±ê¸‰ ì •ë³´
    ok_grade = Column(String(20))
    grade_description = Column(String(200))
    percentile_rank = Column(Float)
    
    # 8ëŒ€ ì˜ì—­ ì ìˆ˜ (JSON)
    dimension_scores = Column(JSON)  # {"ì—…ë¬´ì„±ê³¼": 85.5, "KPIë‹¬ì„±": 90.0, ...}
    dimension_details = Column(JSON)  # ìƒì„¸ ë¶„ì„ ì •ë³´
    
    # AI í”¼ë“œë°±
    ai_strengths = Column(Text)
    ai_improvements = Column(Text)
    ai_feedback = Column(Text)
    ai_processing_time = Column(Float)
    
    # ì›ë³¸ ë°ì´í„°
    raw_text = Column(Text)
    quantitative_data = Column(JSON)
    
    # ë©”íƒ€ë°ì´í„°
    created_at = Column(DateTime, default=datetime.utcnow)
    analysis_metadata = Column(JSON)
    
    # ê´€ê³„
    job = relationship("AnalysisJob", back_populates="scores")

class FileUpload(Base):
    __tablename__ = "file_uploads"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    job_id = Column(UUID(as_uuid=True), ForeignKey("analysis_jobs.id", ondelete="CASCADE"))
    
    # íŒŒì¼ ì •ë³´
    original_filename = Column(String(255), nullable=False)
    stored_filename = Column(String(255))
    file_size = Column(Integer)
    file_type = Column(String(50))
    
    # ë°ì´í„° ì •ë³´
    total_rows = Column(Integer)
    total_columns = Column(Integer)
    
    # ì»¬ëŸ¼ ì •ë³´ (JSON)
    uid_columns = Column(JSON)
    opinion_columns = Column(JSON)
    quantitative_columns = Column(JSON)
    all_columns = Column(JSON)
    
    # ì—…ë¡œë“œ ì •ë³´
    uploaded_at = Column(DateTime, default=datetime.utcnow)
    uploaded_by = Column(String(100))
    
    # ê´€ê³„
    job = relationship("AnalysisJob", back_populates="file_info")

# ì¸ë±ìŠ¤ ì¶”ê°€ë¥¼ ìœ„í•œ ëª…ì‹œì  ì •ì˜
from sqlalchemy import Index

# ë³µí•© ì¸ë±ìŠ¤
Index('idx_job_status_created', AnalysisJob.status, AnalysisJob.created_at)
Index('idx_score_job_uid', EmployeeScore.job_id, EmployeeScore.employee_uid)
Index('idx_score_grade', EmployeeScore.ok_grade)
'''

    # 3. app/db/repositories/base.py - ê¸°ë³¸ Repository
    base_repo_content = '''"""
ê¸°ë³¸ Repository í´ë˜ìŠ¤
"""
from typing import Generic, TypeVar, Type, Optional, List, Dict, Any
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, update, delete
from sqlalchemy.sql import func
from app.db.base import Base
import uuid

ModelType = TypeVar("ModelType", bound=Base)

class BaseRepository(Generic[ModelType]):
    """ê¸°ë³¸ CRUD ì‘ì—…ì„ ìœ„í•œ Repository"""
    
    def __init__(self, model: Type[ModelType], db: AsyncSession):
        self.model = model
        self.db = db
    
    async def get(self, id: uuid.UUID) -> Optional[ModelType]:
        """IDë¡œ ë‹¨ì¼ ë ˆì½”ë“œ ì¡°íšŒ"""
        result = await self.db.execute(
            select(self.model).where(self.model.id == id)
        )
        return result.scalar_one_or_none()
    
    async def get_all(self, skip: int = 0, limit: int = 100) -> List[ModelType]:
        """ëª¨ë“  ë ˆì½”ë“œ ì¡°íšŒ (í˜ì´ì§€ë„¤ì´ì…˜)"""
        result = await self.db.execute(
            select(self.model).offset(skip).limit(limit)
        )
        return list(result.scalars().all())
    
    async def create(self, **kwargs) -> ModelType:
        """ìƒˆ ë ˆì½”ë“œ ìƒì„±"""
        db_obj = self.model(**kwargs)
        self.db.add(db_obj)
        await self.db.commit()
        await self.db.refresh(db_obj)
        return db_obj
    
    async def update(self, id: uuid.UUID, **kwargs) -> Optional[ModelType]:
        """ë ˆì½”ë“œ ì—…ë°ì´íŠ¸"""
        await self.db.execute(
            update(self.model).where(self.model.id == id).values(**kwargs)
        )
        await self.db.commit()
        return await self.get(id)
    
    async def delete(self, id: uuid.UUID) -> bool:
        """ë ˆì½”ë“œ ì‚­ì œ"""
        result = await self.db.execute(
            delete(self.model).where(self.model.id == id)
        )
        await self.db.commit()
        return result.rowcount > 0
    
    async def count(self) -> int:
        """ì „ì²´ ë ˆì½”ë“œ ìˆ˜"""
        result = await self.db.execute(
            select(func.count()).select_from(self.model)
        )
        return result.scalar()
'''

    # 4. app/db/repositories/job_repository.py
    job_repo_content = '''"""
AnalysisJob Repository
"""
from typing import Optional, List
from sqlalchemy import select, and_
from sqlalchemy.orm import selectinload
from datetime import datetime
import uuid

from app.db.repositories.base import BaseRepository
from app.models.models import AnalysisJob, JobStatus
from sqlalchemy.ext.asyncio import AsyncSession

class JobRepository(BaseRepository[AnalysisJob]):
    """ë¶„ì„ ì‘ì—… Repository"""
    
    def __init__(self, db: AsyncSession):
        super().__init__(AnalysisJob, db)
    
    async def get_with_scores(self, job_id: uuid.UUID) -> Optional[AnalysisJob]:
        """ì ìˆ˜ ì •ë³´ì™€ í•¨ê»˜ ì‘ì—… ì¡°íšŒ"""
        result = await self.db.execute(
            select(AnalysisJob)
            .options(selectinload(AnalysisJob.scores))
            .where(AnalysisJob.id == job_id)
        )
        return result.scalar_one_or_none()
    
    async def get_by_status(self, status: JobStatus) -> List[AnalysisJob]:
        """ìƒíƒœë³„ ì‘ì—… ì¡°íšŒ"""
        result = await self.db.execute(
            select(AnalysisJob).where(AnalysisJob.status == status)
        )
        return list(result.scalars().all())
    
    async def get_completed_jobs(self, limit: int = 50) -> List[AnalysisJob]:
        """ì™„ë£Œëœ ì‘ì—… ëª©ë¡ ì¡°íšŒ"""
        result = await self.db.execute(
            select(AnalysisJob)
            .where(AnalysisJob.status == JobStatus.COMPLETED)
            .order_by(AnalysisJob.completed_at.desc())
            .limit(limit)
        )
        return list(result.scalars().all())
    
    async def update_progress(
        self, 
        job_id: uuid.UUID, 
        processed: int, 
        failed: int = 0
    ) -> None:
        """ì‘ì—… ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸"""
        await self.db.execute(
            update(AnalysisJob)
            .where(AnalysisJob.id == job_id)
            .values(
                processed_records=processed,
                failed_records=failed
            )
        )
        await self.db.commit()
    
    async def complete_job(
        self, 
        job_id: uuid.UUID, 
        average_score: float
    ) -> None:
        """ì‘ì—… ì™„ë£Œ ì²˜ë¦¬"""
        await self.db.execute(
            update(AnalysisJob)
            .where(AnalysisJob.id == job_id)
            .values(
                status=JobStatus.COMPLETED,
                completed_at=datetime.utcnow(),
                average_score=average_score
            )
        )
        await self.db.commit()
'''

    # 5. app/core/config/settings.py ì—…ë°ì´íŠ¸
    updated_settings_content = '''"""
ì„¤ì • ê´€ë¦¬ ëª¨ë“ˆ
"""
from typing import Any, Dict, List, Optional, Union
from pydantic_settings import BaseSettings
from pydantic import field_validator
import secrets

class Settings(BaseSettings):
    # ê¸°ë³¸ ì„¤ì •
    PROJECT_NAME: str = "AIRISS v4.0"
    VERSION: str = "4.0.0"
    API_V1_STR: str = "/api/v1"
    DEBUG: bool = True
    
    # ë³´ì•ˆ
    SECRET_KEY: str = secrets.token_urlsafe(32)
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 60 * 24 * 8  # 8 days
    
    # ë°ì´í„°ë² ì´ìŠ¤
    POSTGRES_SERVER: str = "localhost"
    POSTGRES_USER: str = "airiss"
    POSTGRES_PASSWORD: str = "password"
    POSTGRES_DB: str = "airiss_db"
    
    @property
    def DATABASE_URL(self) -> str:
        """ë°ì´í„°ë² ì´ìŠ¤ URL ìƒì„±"""
        return f"postgresql+asyncpg://{self.POSTGRES_USER}:{self.POSTGRES_PASSWORD}@{self.POSTGRES_SERVER}/{self.POSTGRES_DB}"
    
    # Redis
    REDIS_URL: str = "redis://localhost:6379"
    
    # CORS
    BACKEND_CORS_ORIGINS: List[str] = ["http://localhost:3000", "http://localhost:8000"]
    
    # OpenAI
    OPENAI_API_KEY: Optional[str] = None
    OPENAI_MODEL: str = "gpt-3.5-turbo"
    OPENAI_MAX_TOKENS: int = 1200
    
    # íŒŒì¼ ì—…ë¡œë“œ
    UPLOAD_FOLDER: str = "uploads"
    MAX_UPLOAD_SIZE: int = 100 * 1024 * 1024  # 100MB
    ALLOWED_EXTENSIONS: List[str] = [".csv", ".xlsx", ".xls"]
    
    # ë¡œê¹…
    LOG_LEVEL: str = "INFO"
    LOG_FORMAT: str = "json"
    
    class Config:
        case_sensitive = True
        env_file = ".env"

settings = Settings()
'''

    # íŒŒì¼ ìƒì„±
    files = {
        "app/db/base.py": db_base_content,
        "app/models/models.py": models_content,
        "app/db/repositories/base.py": base_repo_content,
        "app/db/repositories/job_repository.py": job_repo_content,
        "app/core/config/settings.py": updated_settings_content
    }
    
    # __init__.py íŒŒì¼ë“¤
    init_files = [
        "app/models/__init__.py",
        "app/db/repositories/__init__.py"
    ]
    
    print("ğŸ“ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ìƒì„± ì¤‘...")
    
    for filepath, content in files.items():
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        # íŒŒì¼ ì“°ê¸°
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content.strip())
        print(f"âœ… {filepath}")
    
    # __init__.py íŒŒì¼ ìƒì„±
    for filepath in init_files:
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        with open(filepath, "w", encoding="utf-8") as f:
            f.write("# AIRISS v4.0\n")
        print(f"âœ… {filepath}")
    
    print("\nâœ… ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ìƒì„± ì™„ë£Œ!")

if __name__ == "__main__":
    create_db_files()