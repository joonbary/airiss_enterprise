# app/services/bias_detection/bias_detector.py
"""
AIRISS v4.0 í¸í–¥ íƒì§€ ì‹œìŠ¤í…œ
ì„±ë³„, ì—°ë ¹, ë¶€ì„œë³„ ê³µì •ì„± ìë™ ê²€ì¦
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
from scipy import stats
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

class BiasDetector:
    """AI í‰ê°€ í¸í–¥ íƒì§€ ë° ê³µì •ì„± ê²€ì¦ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.thresholds = {
            'statistical_parity': 0.1,  # 10% ì´ë‚´ ì°¨ì´ í—ˆìš©
            'equalized_odds': 0.15,     # 15% ì´ë‚´ ì°¨ì´ í—ˆìš©
            'cohen_d': 0.2,             # Small effect size ê¸°ì¤€
            'p_value': 0.05             # í†µê³„ì  ìœ ì˜ì„± ê¸°ì¤€
        }
        
        self.protected_attributes = ['ì„±ë³„', 'ì—°ë ¹ëŒ€', 'ë¶€ì„œ', 'ì§ê¸‰']
        
        logger.info("âœ… AIRISS í¸í–¥ íƒì§€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def detect_bias(self, analysis_results: pd.DataFrame) -> Dict[str, any]:
        """ì¢…í•©ì ì¸ í¸í–¥ íƒì§€ ìˆ˜í–‰"""
        
        bias_report = {
            'summary': {
                'total_analyzed': len(analysis_results),
                'bias_detected': False,
                'risk_level': 'LOW',
                'timestamp': datetime.now().isoformat()
            },
            'detailed_analysis': {},
            'recommendations': []
        }
        
        # ê° ë³´í˜¸ ì†ì„±ë³„ í¸í–¥ ë¶„ì„
        for attr in self.protected_attributes:
            if attr in analysis_results.columns:
                attr_analysis = self._analyze_attribute_bias(
                    analysis_results, 
                    attr, 
                    'hybrid_score'
                )
                bias_report['detailed_analysis'][attr] = attr_analysis
                
                if attr_analysis['bias_detected']:
                    bias_report['summary']['bias_detected'] = True
        
        # êµì°¨ í¸í–¥ ë¶„ì„ (ì˜ˆ: ì„±ë³„ x ì—°ë ¹ëŒ€)
        if 'ì„±ë³„' in analysis_results.columns and 'ì—°ë ¹ëŒ€' in analysis_results.columns:
            intersectional_bias = self._analyze_intersectional_bias(
                analysis_results, 
                ['ì„±ë³„', 'ì—°ë ¹ëŒ€'], 
                'hybrid_score'
            )
            bias_report['detailed_analysis']['intersectional'] = intersectional_bias
        
        # ìœ„í—˜ ìˆ˜ì¤€ í‰ê°€
        bias_report['summary']['risk_level'] = self._assess_risk_level(bias_report)
        
        # ê¶Œê³ ì‚¬í•­ ìƒì„±
        bias_report['recommendations'] = self._generate_recommendations(bias_report)
        
        return bias_report
    
    def _analyze_attribute_bias(self, 
                               df: pd.DataFrame, 
                               attribute: str, 
                               score_column: str) -> Dict:
        """íŠ¹ì • ì†ì„±ì— ëŒ€í•œ í¸í–¥ ë¶„ì„"""
        
        groups = df.groupby(attribute)[score_column]
        group_stats = groups.agg(['mean', 'std', 'count']).to_dict('index')
        
        # í†µê³„ì  í˜•í‰ì„± (Statistical Parity) ê³„ì‚°
        means = [stats['mean'] for stats in group_stats.values()]
        max_diff = max(means) - min(means)
        avg_mean = np.mean(means)
        parity_ratio = max_diff / avg_mean if avg_mean > 0 else 0
        
        # ANOVA ê²€ì •
        group_scores = [group[score_column].values for name, group in df.groupby(attribute)]
        f_stat, p_value = stats.f_oneway(*group_scores) if len(group_scores) > 1 else (0, 1)
        
        # Cohen's d íš¨ê³¼ í¬ê¸° ê³„ì‚° (ìµœëŒ€/ìµœì†Œ ê·¸ë£¹ ê°„)
        if len(means) >= 2:
            sorted_groups = sorted(group_stats.items(), key=lambda x: x[1]['mean'])
            low_group = df[df[attribute] == sorted_groups[0][0]][score_column]
            high_group = df[df[attribute] == sorted_groups[-1][0]][score_column]
            cohen_d = self._calculate_cohen_d(low_group, high_group)
        else:
            cohen_d = 0
        
        # í¸í–¥ íŒì •
        bias_detected = (
            parity_ratio > self.thresholds['statistical_parity'] or
            p_value < self.thresholds['p_value'] or
            abs(cohen_d) > self.thresholds['cohen_d']
        )
        
        return {
            'bias_detected': bias_detected,
            'group_statistics': group_stats,
            'statistical_tests': {
                'parity_ratio': round(parity_ratio, 3),
                'anova_f_stat': round(f_stat, 3),
                'p_value': round(p_value, 4),
                'cohen_d': round(cohen_d, 3)
            },
            'interpretation': self._interpret_bias_results(
                parity_ratio, p_value, cohen_d, attribute
            )
        }
    
    def _analyze_intersectional_bias(self, 
                                    df: pd.DataFrame, 
                                    attributes: List[str], 
                                    score_column: str) -> Dict:
        """êµì°¨ ì†ì„± í¸í–¥ ë¶„ì„ (ì˜ˆ: ì—¬ì„± x 40ëŒ€)"""
        
        # êµì°¨ ê·¸ë£¹ ìƒì„±
        df['intersectional_group'] = df[attributes].apply(
            lambda x: '_'.join(x.astype(str)), axis=1
        )
        
        # êµì°¨ ê·¸ë£¹ë³„ ë¶„ì„
        intersectional_analysis = self._analyze_attribute_bias(
            df, 'intersectional_group', score_column
        )
        
        # ê°€ì¥ ë¶ˆë¦¬í•œ ê·¸ë£¹ ì‹ë³„
        group_means = intersectional_analysis['group_statistics']
        worst_group = min(group_means.items(), key=lambda x: x[1]['mean'])[0]
        best_group = max(group_means.items(), key=lambda x: x[1]['mean'])[0]
        
        intersectional_analysis['most_disadvantaged'] = worst_group
        intersectional_analysis['most_advantaged'] = best_group
        intersectional_analysis['gap'] = (
            group_means[best_group]['mean'] - group_means[worst_group]['mean']
        )
        
        return intersectional_analysis
    
    def _calculate_cohen_d(self, group1: pd.Series, group2: pd.Series) -> float:
        """Cohen's d íš¨ê³¼ í¬ê¸° ê³„ì‚°"""
        n1, n2 = len(group1), len(group2)
        var1, var2 = group1.var(), group2.var()
        
        # Pooled standard deviation
        pooled_std = np.sqrt(((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2))
        
        # Cohen's d
        if pooled_std > 0:
            return (group1.mean() - group2.mean()) / pooled_std
        return 0
    
    def _assess_risk_level(self, bias_report: Dict) -> str:
        """í¸í–¥ ìœ„í—˜ ìˆ˜ì¤€ í‰ê°€"""
        
        bias_count = sum(
            1 for analysis in bias_report['detailed_analysis'].values()
            if analysis.get('bias_detected', False)
        )
        
        # êµì°¨ í¸í–¥ì´ ìˆìœ¼ë©´ ìœ„í—˜ë„ ìƒìŠ¹
        if 'intersectional' in bias_report['detailed_analysis']:
            if bias_report['detailed_analysis']['intersectional'].get('bias_detected'):
                bias_count += 1
        
        if bias_count == 0:
            return 'LOW'
        elif bias_count == 1:
            return 'MEDIUM'
        else:
            return 'HIGH'
    
    def _interpret_bias_results(self, 
                               parity_ratio: float, 
                               p_value: float, 
                               cohen_d: float,
                               attribute: str) -> str:
        """í¸í–¥ ë¶„ì„ ê²°ê³¼ í•´ì„"""
        
        interpretations = []
        
        if parity_ratio > self.thresholds['statistical_parity']:
            interpretations.append(
                f"{attribute}ë³„ í‰ê·  ì ìˆ˜ ì°¨ì´ê°€ {parity_ratio*100:.1f}%ë¡œ "
                f"í—ˆìš© ê¸°ì¤€({self.thresholds['statistical_parity']*100}%)ì„ ì´ˆê³¼í•©ë‹ˆë‹¤."
            )
        
        if p_value < self.thresholds['p_value']:
            interpretations.append(
                f"í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤ (p={p_value:.4f})."
            )
        
        if abs(cohen_d) > self.thresholds['cohen_d']:
            effect_size = (
                "ì‘ì€" if abs(cohen_d) < 0.5 else
                "ì¤‘ê°„" if abs(cohen_d) < 0.8 else
                "í°"
            )
            interpretations.append(
                f"{effect_size} íš¨ê³¼ í¬ê¸°(d={cohen_d:.2f})ê°€ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤."
            )
        
        if not interpretations:
            return f"{attribute}ì— ëŒ€í•œ ìœ ì˜ë¯¸í•œ í¸í–¥ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        return " ".join(interpretations)
    
    def _generate_recommendations(self, bias_report: Dict) -> List[str]:
        """í¸í–¥ ì™„í™”ë¥¼ ìœ„í•œ ê¶Œê³ ì‚¬í•­ ìƒì„±"""
        
        recommendations = []
        
        if not bias_report['summary']['bias_detected']:
            recommendations.append(
                "âœ… í˜„ì¬ ë¶„ì„ ê²°ê³¼ì—ì„œ ìœ ì˜ë¯¸í•œ í¸í–¥ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                "ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            )
            return recommendations
        
        # ì†ì„±ë³„ ê¶Œê³ ì‚¬í•­
        for attr, analysis in bias_report['detailed_analysis'].items():
            if analysis.get('bias_detected'):
                if attr == 'ì„±ë³„':
                    recommendations.append(
                        "âš ï¸ ì„±ë³„ í¸í–¥ ì™„í™”: í‰ê°€ ê¸°ì¤€ì—ì„œ ì„±ë³„ ì¤‘ë¦½ì  ì–¸ì–´ ì‚¬ìš©ì„ ê°•í™”í•˜ê³ , "
                        "ë‹¤ì–‘ì„± ê´€ì ì˜ í‰ê°€ìë¥¼ í¬í•¨ì‹œí‚¤ì„¸ìš”."
                    )
                elif attr == 'ì—°ë ¹ëŒ€':
                    recommendations.append(
                        "âš ï¸ ì—°ë ¹ í¸í–¥ ì™„í™”: ì„¸ëŒ€ë³„ ì—…ë¬´ ìŠ¤íƒ€ì¼ ì°¨ì´ë¥¼ ì¸ì •í•˜ê³ , "
                        "ì—°ë ¹ ì¤‘ë¦½ì ì¸ ì„±ê³¼ ì§€í‘œë¥¼ ê°œë°œí•˜ì„¸ìš”."
                    )
                elif attr == 'ë¶€ì„œ':
                    recommendations.append(
                        "âš ï¸ ë¶€ì„œ í¸í–¥ ì™„í™”: ë¶€ì„œë³„ ì—…ë¬´ íŠ¹ì„±ì„ ë°˜ì˜í•œ ë§ì¶¤í˜• í‰ê°€ ê¸°ì¤€ì„ "
                        "ê°œë°œí•˜ê³ , í¬ë¡œìŠ¤ í‘ì…”ë„ í‰ê°€ë¥¼ ë„ì…í•˜ì„¸ìš”."
                    )
        
        # ìœ„í—˜ ìˆ˜ì¤€ë³„ ì¶”ê°€ ê¶Œê³ 
        risk_level = bias_report['summary']['risk_level']
        if risk_level == 'HIGH':
            recommendations.append(
                "ğŸš¨ ë†’ì€ ìœ„í—˜: ì¦‰ì‹œ AI ëª¨ë¸ ì¬í›ˆë ¨ê³¼ í‰ê°€ í”„ë¡œì„¸ìŠ¤ ì „ë©´ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤. "
                "ì™¸ë¶€ ì „ë¬¸ê°€ ìë¬¸ì„ ê³ ë ¤í•˜ì„¸ìš”."
            )
        elif risk_level == 'MEDIUM':
            recommendations.append(
                "âš¡ ì¤‘ê°„ ìœ„í—˜: í¸í–¥ ì™„í™” ì¡°ì¹˜ë¥¼ ìš°ì„ ìˆœìœ„ë¡œ ì‹¤í–‰í•˜ê³ , "
                "ì›”ë³„ í¸í–¥ ëª¨ë‹ˆí„°ë§ì„ ê°•í™”í•˜ì„¸ìš”."
            )
        
        # ì¼ë°˜ ê¶Œê³ ì‚¬í•­
        recommendations.extend([
            "ğŸ’¡ ì •ê¸°ì ì¸ í¸í–¥ ê°ì‚¬ ì‹¤ì‹œ (ìµœì†Œ ë¶„ê¸°ë³„)",
            "ğŸ’¡ ë‹¤ì–‘ì„± êµìœ¡ í”„ë¡œê·¸ë¨ ê°•í™”",
            "ğŸ’¡ AI í‰ê°€ ê²°ê³¼ì— ëŒ€í•œ ì¸ê°„ ê²€í†  í”„ë¡œì„¸ìŠ¤ ê°•í™”"
        ])
        
        return recommendations

    def generate_fairness_report(self, 
                                analysis_results: pd.DataFrame,
                                output_format: str = 'html') -> str:
        """ê³µì •ì„± ë³´ê³ ì„œ ìƒì„±"""
        
        bias_report = self.detect_bias(analysis_results)
        
        if output_format == 'html':
            return self._generate_html_report(bias_report)
        elif output_format == 'json':
            import json
            return json.dumps(bias_report, ensure_ascii=False, indent=2)
        else:
            return str(bias_report)
    
    def _generate_html_report(self, bias_report: Dict) -> str:
        """HTML í˜•ì‹ì˜ ê³µì •ì„± ë³´ê³ ì„œ ìƒì„±"""
        
        risk_colors = {
            'LOW': '#4CAF50',
            'MEDIUM': '#FF9800',
            'HIGH': '#f44336'
        }
        
        risk_color = risk_colors.get(bias_report['summary']['risk_level'], '#666')
        
        html = f"""
        <div style="font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto;">
            <h2 style="color: #FF5722;">ğŸ” AIRISS v4.0 ê³µì •ì„± ë¶„ì„ ë³´ê³ ì„œ</h2>
            
            <div style="background: #f5f5f5; padding: 20px; border-radius: 8px; margin: 20px 0;">
                <h3>ğŸ“Š ìš”ì•½</h3>
                <p><strong>ë¶„ì„ ëŒ€ìƒ:</strong> {bias_report['summary']['total_analyzed']}ëª…</p>
                <p><strong>í¸í–¥ íƒì§€:</strong> {'ğŸš¨ ë°œê²¬ë¨' if bias_report['summary']['bias_detected'] else 'âœ… ë°œê²¬ë˜ì§€ ì•ŠìŒ'}</p>
                <p><strong>ìœ„í—˜ ìˆ˜ì¤€:</strong> <span style="color: {risk_color}; font-weight: bold;">{bias_report['summary']['risk_level']}</span></p>
                <p><strong>ë¶„ì„ ì‹œê°„:</strong> {bias_report['summary']['timestamp']}</p>
            </div>
            
            <div style="margin: 20px 0;">
                <h3>ğŸ“ˆ ìƒì„¸ ë¶„ì„ ê²°ê³¼</h3>
        """
        
        for attr, analysis in bias_report['detailed_analysis'].items():
            if attr != 'intersectional':
                bias_status = 'ğŸš¨ í¸í–¥ ë°œê²¬' if analysis['bias_detected'] else 'âœ… ì •ìƒ'
                html += f"""
                <div style="background: white; padding: 15px; border: 1px solid #ddd; margin: 10px 0; border-radius: 5px;">
                    <h4>{attr} ë¶„ì„ - {bias_status}</h4>
                    <p>{analysis['interpretation']}</p>
                    <ul style="font-size: 0.9em; color: #666;">
                        <li>í˜•í‰ì„± ë¹„ìœ¨: {analysis['statistical_tests']['parity_ratio']}</li>
                        <li>p-value: {analysis['statistical_tests']['p_value']}</li>
                        <li>íš¨ê³¼ í¬ê¸°(Cohen's d): {analysis['statistical_tests']['cohen_d']}</li>
                    </ul>
                </div>
                """
        
        # ê¶Œê³ ì‚¬í•­
        html += """
            <div style="margin: 20px 0;">
                <h3>ğŸ’¡ ê¶Œê³ ì‚¬í•­</h3>
                <ul>
        """
        
        for rec in bias_report['recommendations']:
            html += f"<li>{rec}</li>"
        
        html += """
                </ul>
            </div>
        </div>
        """
        
        return html
