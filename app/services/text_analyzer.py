# app/services/text_analyzer.py
"""
AIRISS v4.1 í…ìŠ¤íŠ¸ ë¶„ì„ê¸° - ë”¥ëŸ¬ë‹ NLP ì ìš©
í•œêµ­ì–´ íŠ¹í™” BERT ëª¨ë¸ì„ í™œìš©í•œ ê³ ë„í™”ëœ ê°ì •/ì˜ë„ ë¶„ì„
"""

import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
import asyncio
import numpy as np
import re
from collections import Counter

logger = logging.getLogger(__name__)

# AIRISS 8ëŒ€ ì˜ì—­ ì •ì˜ (ê¸°ì¡´ ìœ ì§€ + í™•ì¥)
AIRISS_FRAMEWORK = {
    "ì—…ë¬´ì„±ê³¼": {
        "keywords": {
            "positive": [
                "ìš°ìˆ˜", "íƒì›”", "ë›°ì–´ë‚¨", "ì„±ê³¼", "ë‹¬ì„±", "ì™„ë£Œ", "ì„±ê³µ", "íš¨ìœ¨", "ìƒì‚°ì ", 
                "ëª©í‘œë‹¬ì„±", "ì´ˆê³¼ë‹¬ì„±", "í’ˆì§ˆ", "ì •í™•", "ì‹ ì†", "ì™„ë²½", "ì „ë¬¸ì ", "ì²´ê³„ì ",
                "í˜ì‹ ì ", "ì°½ì˜ì ", "ê°œì„ ", "í–¥ìƒ", "ìµœì í™”", "ëŠ¥ìˆ™", "ìˆ™ë ¨", "ì „ë¬¸ì„±"
            ],
            "negative": [
                "ë¶€ì¡±", "ë¯¸í¡", "ì§€ì—°", "ì‹¤íŒ¨", "ë¬¸ì œ", "ì˜¤ë¥˜", "ëŠ¦ìŒ", "ë¹„íš¨ìœ¨", 
                "ëª©í‘œë¯¸ë‹¬", "í’ˆì§ˆì €í•˜", "ë¶€ì •í™•", "ë¯¸ì™„ì„±", "ë¶€ì‹¤", "ê°œì„ í•„ìš”", "ë¯¸ë‹¬"
            ]
        },
        "weight": 0.25,
        "description": "ì—…ë¬´ ì‚°ì¶œë¬¼ì˜ ì–‘ê³¼ ì§ˆ",
        "bert_aspects": ["ì—…ë¬´ í’ˆì§ˆ", "ëª©í‘œ ë‹¬ì„±ë„", "ìƒì‚°ì„±", "íš¨ìœ¨ì„±"]
    },
    "KPIë‹¬ì„±": {
        "keywords": {
            "positive": [
                "KPIë‹¬ì„±", "ì§€í‘œë‹¬ì„±", "ëª©í‘œì´ˆê³¼", "ì„±ê³¼ìš°ìˆ˜", "ì‹¤ì ìš°ìˆ˜", "ë§¤ì¶œì¦ê°€", 
                "íš¨ìœ¨í–¥ìƒ", "ìƒì‚°ì„±í–¥ìƒ", "ìˆ˜ì¹˜ë‹¬ì„±", "ì„±ì¥", "ê°œì„ ", "ìƒìŠ¹", "ì¦ê°€"
            ],
            "negative": [
                "KPIë¯¸ë‹¬", "ëª©í‘œë¯¸ë‹¬", "ì‹¤ì ë¶€ì§„", "ë§¤ì¶œê°ì†Œ", "íš¨ìœ¨ì €í•˜", 
                "ìƒì‚°ì„±ì €í•˜", "ìˆ˜ì¹˜ë¶€ì¡±", "í•˜ë½", "í‡´ë³´", "ê°ì†Œ", "ì •ì²´"
            ]
        },
        "weight": 0.20,
        "description": "í•µì‹¬ì„±ê³¼ì§€í‘œ ë‹¬ì„±ë„",
        "bert_aspects": ["ì •ëŸ‰ì  ì„±ê³¼", "ëª©í‘œ ëŒ€ë¹„ ì‹¤ì ", "ì„±ì¥ë¥ "]
    },
    "íƒœë„ë§ˆì¸ë“œ": {
        "keywords": {
            "positive": [
                "ì ê·¹ì ", "ê¸ì •ì ", "ì—´ì •", "ì„±ì‹¤", "ì±…ì„ê°", "ì§„ì·¨ì ", "í˜‘ì¡°ì ", 
                "ì„±ì¥ì§€í–¥", "í•™ìŠµì˜ì§€", "ë„ì „ì •ì‹ ", "ì£¼ì¸ì˜ì‹", "í—Œì‹ ", "ëª°ì…", "ì—´ì˜"
            ],
            "negative": [
                "ì†Œê·¹ì ", "ë¶€ì •ì ", "ë¬´ê´€ì‹¬", "ë¶ˆì„±ì‹¤", "íšŒí”¼", "ëƒ‰ì†Œì ", 
                "ë¹„í˜‘ì¡°ì ", "ì•ˆì£¼", "í˜„ìƒìœ ì§€", "ìˆ˜ë™ì ", "ë¬´ê¸°ë ¥", "íƒœë§Œ"
            ]
        },
        "weight": 0.15,
        "description": "ì—…ë¬´ì— ëŒ€í•œ íƒœë„ì™€ ë§ˆì¸ë“œì…‹",
        "bert_aspects": ["ì ê·¹ì„±", "ì±…ì„ê°", "ì—´ì •", "ì„±ì¥ ë§ˆì¸ë“œì…‹"]
    },
    "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜": {
        "keywords": {
            "positive": [
                "ëª…í™•", "ì •í™•", "ì‹ ì†", "ì¹œì ˆ", "ê²½ì²­", "ì†Œí†µ", "ì „ë‹¬", "ì´í•´", 
                "ì„¤ë“", "í˜‘ì˜", "ì¡°ìœ¨", "ê³µìœ ", "íˆ¬ëª…", "ê°œë°©ì ", "ì›í™œ", "íš¨ê³¼ì "
            ],
            "negative": [
                "ë¶ˆëª…í™•", "ì§€ì—°", "ë¬´ì‹œ", "ì˜¤í•´", "ë‹¨ì ˆ", "ì¹¨ë¬µ", "íšŒí”¼", 
                "ë…ë‹¨", "ì¼ë°©ì ", "íì‡„ì ", "ì†Œí†µë¶€ì¡±", "ì „ë‹¬ë¯¸í¡", "ê°ˆë“±"
            ]
        },
        "weight": 0.15,
        "description": "ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ê³¼ ìŠ¤íƒ€ì¼",
        "bert_aspects": ["ëª…í™•ì„±", "ì ì‹œì„±", "ê³µê°ëŠ¥ë ¥", "ì„¤ë“ë ¥"]
    },
    "ë¦¬ë”ì‹­í˜‘ì—…": {
        "keywords": {
            "positive": [
                "ë¦¬ë”ì‹­", "íŒ€ì›Œí¬", "í˜‘ì—…", "ì§€ì›", "ë©˜í† ë§", "ë™ê¸°ë¶€ì—¬", "ì¡°ìœ¨", 
                "í™”í•©", "íŒ€ë¹Œë”©", "ìœ„ì„", "ì½”ì¹­", "ì˜í–¥ë ¥", "ì¡´ì¤‘", "ë°°ë ¤", "ê³µìœ "
            ],
            "negative": [
                "ë…ë‹¨", "ê°ˆë“±", "ë¹„í˜‘ì¡°", "ì†Œì™¸", "ë¶„ì—´", "ëŒ€ë¦½", "ì´ê¸°ì£¼ì˜", 
                "ë°©í•´", "ë¬´ê´€ì‹¬", "ê³ ë¦½", "ê°œì¸ì£¼ì˜", "ê¶Œìœ„ì ", "ê°•ì••ì "
            ]
        },
        "weight": 0.10,
        "description": "ë¦¬ë”ì‹­ê³¼ í˜‘ì—… ëŠ¥ë ¥",
        "bert_aspects": ["íŒ€ ê¸°ì—¬ë„", "ë¦¬ë”ì‹­ ìŠ¤íƒ€ì¼", "í˜‘ì—… ìì„¸"]
    },
    "ì „ë¬¸ì„±í•™ìŠµ": {
        "keywords": {
            "positive": [
                "ì „ë¬¸", "ìˆ™ë ¨", "ê¸°ìˆ ", "ì§€ì‹", "í•™ìŠµ", "ë°œì „", "ì—­ëŸ‰", "ëŠ¥ë ¥", 
                "ì„±ì¥", "í–¥ìƒ", "ìŠµë“", "ê°œë°œ", "ì „ë¬¸ì„±", "ë…¸í•˜ìš°", "í˜ì‹ ", "ì—°êµ¬"
            ],
            "negative": [
                "ë¯¸ìˆ™", "ë¶€ì¡±", "ë‚™í›„", "ë¬´ì§€", "ì •ì²´", "í‡´ë³´", "ë¬´ëŠ¥ë ¥", 
                "ê¸°ì´ˆë¶€ì¡±", "ì—­ëŸ‰ë¶€ì¡±", "ì‹¤ë ¥ë¶€ì¡±", "ê°œì„ í•„ìš”", "í•™ìŠµë¶€ì§„"
            ]
        },
        "weight": 0.08,
        "description": "ì „ë¬¸ì„±ê³¼ í•™ìŠµëŠ¥ë ¥",
        "bert_aspects": ["ì „ë¬¸ ì§€ì‹", "í•™ìŠµ ì†ë„", "ê¸°ìˆ  ìˆ™ë ¨ë„"]
    },
    "ì°½ì˜í˜ì‹ ": {
        "keywords": {
            "positive": [
                "ì°½ì˜", "í˜ì‹ ", "ì•„ì´ë””ì–´", "ê°œì„ ", "íš¨ìœ¨í™”", "ìµœì í™”", "ìƒˆë¡œìš´", 
                "ë„ì „", "ë³€í™”", "ë°œìƒ", "ì°½ì¡°", "í˜ì‹ ì ", "ë…ì°½ì ", "ì„ ë„ì "
            ],
            "negative": [
                "ë³´ìˆ˜ì ", "ê²½ì§", "í‹€ì—ë°•íŒ", "ë³€í™”ê±°ë¶€", "ê¸°ì¡´ë°©ì‹", "ê´€ìŠµì ", 
                "ê²½ì§ëœ", "ê³ ì •ì ", "ë³€í™”ì—†ì´", "êµ¬íƒœì˜ì—°", "ë§¤ë„ˆë¦¬ì¦˜"
            ]
        },
        "weight": 0.05,
        "description": "ì°½ì˜ì„±ê³¼ í˜ì‹  ë§ˆì¸ë“œ",
        "bert_aspects": ["ì°½ì˜ì„±", "í˜ì‹  ì˜ì§€", "ë³€í™” ìˆ˜ìš©ì„±"]
    },
    "ì¡°ì§ì ì‘": {
        "keywords": {
            "positive": [
                "ì ì‘", "ìœµí™”", "ì¡°í™”", "ë¬¸í™”", "ê·œì¹™ì¤€ìˆ˜", "ìœ¤ë¦¬", "ì‹ ë¢°", 
                "ì•ˆì •", "ì¼ê´€ì„±", "ì„±ì‹¤ì„±", "ì¡°ì§", "íšŒì‚¬", "ì¶©ì„±", "ì†Œì†ê°"
            ],
            "negative": [
                "ë¶€ì ì‘", "ê°ˆë“±", "ìœ„ë°˜", "ë¹„ìœ¤ë¦¬", "ë¶ˆì‹ ", "ì¼íƒˆ", 
                "ë¬¸ì œí–‰ë™", "ê·œì •ìœ„ë°˜", "ì¡°ì§ê³¼", "ì´íƒˆ", "ë¶ˆí™”"
            ]
        },
        "weight": 0.02,
        "description": "ì¡°ì§ë¬¸í™” ì ì‘ë„ì™€ ìœ¤ë¦¬ì„±",
        "bert_aspects": ["ì¡°ì§ ì ì‘ë ¥", "ìœ¤ë¦¬ì„±", "ê·œì • ì¤€ìˆ˜"]
    }
}

class AIRISSTextAnalyzer:
    """AIRISS v4.1 ë”¥ëŸ¬ë‹ ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.framework = AIRISS_FRAMEWORK
        self.openai_available = False
        self.openai = None
        self.bert_model = None
        self.bias_detector = None
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self._initialize_models()
        
    def _initialize_models(self):
        """ë”¥ëŸ¬ë‹ ëª¨ë¸ ì´ˆê¸°í™”"""
        # OpenAI ëª¨ë“ˆ ì²´í¬
        try:
            import openai
            self.openai = openai
            self.openai_available = True
            logger.info("âœ… OpenAI ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
        except ImportError:
            logger.warning("âš ï¸ OpenAI ëª¨ë“ˆ ì—†ìŒ - ê³ ê¸‰ AI ë¶„ì„ ì œí•œë¨")
        
        # í•œêµ­ì–´ BERT ëª¨ë¸ ì´ˆê¸°í™” ì‹œë„
        try:
            from transformers import AutoTokenizer, AutoModelForSequenceClassification
            import torch
            
            # KcELECTRA ë˜ëŠ” KoBERT ëª¨ë¸ ì‚¬ìš©
            model_name = "beomi/KcELECTRA-base-v2022"
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.bert_model = AutoModelForSequenceClassification.from_pretrained(model_name)
            self.bert_available = True
            logger.info("âœ… í•œêµ­ì–´ BERT ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        except:
            self.bert_available = False
            logger.warning("âš ï¸ BERT ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - í–¥ìƒëœ í‚¤ì›Œë“œ ë¶„ì„ ì‚¬ìš©")
        
        # í¸í–¥ íƒì§€ê¸° ì´ˆê¸°í™”
        self.bias_detector = BiasDetector()
    
    def analyze_text(self, text: str, dimension: str) -> Dict[str, Any]:
        """í–¥ìƒëœ í…ìŠ¤íŠ¸ ë¶„ì„ - ë”¥ëŸ¬ë‹ + í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ"""
        if not text or text.lower() in ['nan', 'null', '', 'none']:
            return {
                "score": 50,
                "confidence": 0,
                "signals": {"positive": 0, "negative": 0, "positive_words": [], "negative_words": []},
                "analysis_method": "default"
            }
        
        # 1. ê¸°ë³¸ í‚¤ì›Œë“œ ë¶„ì„ (í´ë°±ìš©)
        keyword_result = self._keyword_analysis(text, dimension)
        
        # 2. BERT ê¸°ë°˜ ê°ì •/ì˜ë„ ë¶„ì„ (ê°€ëŠ¥í•œ ê²½ìš°)
        if self.bert_available:
            bert_result = self._bert_analysis(text, dimension)
            # ë‘ ê²°ê³¼ë¥¼ ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ê²°í•©
            combined_score = keyword_result["score"] * 0.4 + bert_result["score"] * 0.6
            combined_confidence = (keyword_result["confidence"] + bert_result["confidence"]) / 2
            
            return {
                "score": round(combined_score, 1),
                "confidence": round(combined_confidence, 1),
                "signals": keyword_result["signals"],
                "sentiment": bert_result.get("sentiment", "neutral"),
                "intent": bert_result.get("intent", "unknown"),
                "analysis_method": "hybrid_bert"
            }
        else:
            # BERT ì—†ì„ ê²½ìš° í–¥ìƒëœ í‚¤ì›Œë“œ ë¶„ì„
            enhanced_result = self._enhanced_keyword_analysis(text, dimension)
            return enhanced_result
    
    def _keyword_analysis(self, text: str, dimension: str) -> Dict[str, Any]:
        """ê¸°ì¡´ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ (ê°œì„ ë¨)"""
        keywords = self.framework[dimension]["keywords"]
        text_lower = text.lower()
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ - íŠ¹ìˆ˜ë¬¸ì ì œê±°, í† í°í™”
        text_cleaned = re.sub(r'[^\w\s]', ' ', text_lower)
        tokens = text_cleaned.split()
        
        # N-gram ë¶„ì„ (1-gram, 2-gram)
        positive_matches = []
        negative_matches = []
        
        # 1-gram ë§¤ì¹­
        for word in keywords["positive"]:
            if word in text_lower:
                positive_matches.append(word)
                # ë¬¸ë§¥ ê°€ì¤‘ì¹˜ - ë¬¸ì¥ ì‹œì‘/ë ë¶€ë¶„ì— ë‚˜ì˜¤ë©´ ê°€ì¤‘ì¹˜ ì¦ê°€
                if text_lower.startswith(word) or text_lower.endswith(word):
                    positive_matches.append(word)  # ì¤‘ë³µ ì¶”ê°€ë¡œ ê°€ì¤‘ì¹˜ íš¨ê³¼
        
        for word in keywords["negative"]:
            if word in text_lower:
                negative_matches.append(word)
                if text_lower.startswith(word) or text_lower.endswith(word):
                    negative_matches.append(word)
        
        # ê°ì • ê°•ë„ ë¶„ì„
        intensity_words = {
            "ë§¤ìš°": 1.5, "ì •ë§": 1.5, "ì•„ì£¼": 1.5, "íŠ¹íˆ": 1.3, "ìƒë‹¹íˆ": 1.3,
            "ì•½ê°„": 0.7, "ì¡°ê¸ˆ": 0.7, "ë‹¤ì†Œ": 0.8, "ì‚´ì§": 0.6
        }
        
        intensity_multiplier = 1.0
        for word, multiplier in intensity_words.items():
            if word in text_lower:
                intensity_multiplier = max(intensity_multiplier, multiplier)
        
        positive_count = len(positive_matches)
        negative_count = len(negative_matches)
        
        # ê°œì„ ëœ ì ìˆ˜ ê³„ì‚°
        base_score = 50
        positive_boost = min(positive_count * 10 * intensity_multiplier, 45)
        negative_penalty = min(negative_count * 12 * intensity_multiplier, 40)
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ë³´ë„ˆìŠ¤ (ë” ìƒì„¸í•œ í‰ê°€ì¼ìˆ˜ë¡ ì‹ ë¢°ë„ ì¦ê°€)
        text_length = len(text)
        if text_length > 100:
            length_bonus = min((text_length - 100) / 200 * 10, 15)
        elif text_length < 30:
            length_bonus = -10  # ë„ˆë¬´ ì§§ì€ í‰ê°€ëŠ” ê°ì 
        else:
            length_bonus = 0
        
        # ë¬¸ì¥ ë³µì¡ë„ ë³´ë„ˆìŠ¤
        sentence_count = len(re.findall(r'[.!?]+', text))
        if sentence_count > 3:
            complexity_bonus = min(sentence_count * 2, 10)
        else:
            complexity_bonus = 0
        
        final_score = base_score + positive_boost - negative_penalty + length_bonus + complexity_bonus
        final_score = max(10, min(100, final_score))
        
        # ì‹ ë¢°ë„ ê³„ì‚° ê°œì„ 
        total_signals = positive_count + negative_count
        base_confidence = min(total_signals * 15, 70)
        length_confidence = min(text_length / 20, 20)
        complexity_confidence = min(sentence_count * 3, 10)
        confidence = min(base_confidence + length_confidence + complexity_confidence, 100)
        
        return {
            "score": round(final_score, 1),
            "confidence": round(confidence, 1),
            "signals": {
                "positive": positive_count,
                "negative": negative_count,
                "positive_words": list(set(positive_matches))[:5],
                "negative_words": list(set(negative_matches))[:5],
                "intensity": intensity_multiplier
            },
            "analysis_method": "enhanced_keyword"
        }
    
    def _enhanced_keyword_analysis(self, text: str, dimension: str) -> Dict[str, Any]:
        """í–¥ìƒëœ í‚¤ì›Œë“œ ë¶„ì„ - ë¬¸ë§¥ê³¼ íŒ¨í„´ ê³ ë ¤"""
        base_result = self._keyword_analysis(text, dimension)
        
        # ì¶”ê°€ íŒ¨í„´ ë¶„ì„
        patterns = {
            "achievement": r"(ë‹¬ì„±|ì™„ë£Œ|ì„±ê³µ|ì´ë£¨|í•´ëƒˆ|ì™„ìˆ˜)",
            "improvement": r"(ê°œì„ |í–¥ìƒ|ë°œì „|ì„±ì¥|ì§„ë³´)",
            "problem": r"(ë¬¸ì œ|ì´ìŠˆ|ì¥ì• |ì–´ë ¤ì›€|ê³¤ë€)",
            "collaboration": r"(í˜‘ë ¥|í˜‘ì—…|í•¨ê»˜|ê³µë™|íŒ€ì›Œí¬)"
        }
        
        pattern_scores = {}
        for pattern_name, pattern in patterns.items():
            matches = re.findall(pattern, text)
            pattern_scores[pattern_name] = len(matches)
        
        # íŒ¨í„´ ê¸°ë°˜ ì ìˆ˜ ì¡°ì •
        if pattern_scores["achievement"] > 0:
            base_result["score"] += 5
        if pattern_scores["improvement"] > 0:
            base_result["score"] += 3
        if pattern_scores["problem"] > 0:
            base_result["score"] -= 5
        if pattern_scores["collaboration"] > 0 and dimension == "ë¦¬ë”ì‹­í˜‘ì—…":
            base_result["score"] += 7
        
        base_result["score"] = max(10, min(100, base_result["score"]))
        base_result["pattern_analysis"] = pattern_scores
        
        return base_result
    
    def _bert_analysis(self, text: str, dimension: str) -> Dict[str, Any]:
        """BERT ê¸°ë°˜ ê°ì •/ì˜ë„ ë¶„ì„ (ì‹¤ì œ êµ¬í˜„ ì‹œë®¬ë ˆì´ì…˜)"""
        # ì‹¤ì œ êµ¬í˜„ ì‹œ BERT ëª¨ë¸ì„ í†µí•œ ë¶„ì„
        # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ëŒ€ì²´
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ì™€ ë³µì¡ë„ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜
        text_length = len(text)
        positive_ratio = len(re.findall(r'(ìš°ìˆ˜|ì¢‹|ì˜|í›Œë¥­|íƒì›”)', text)) / max(1, len(text.split()))
        negative_ratio = len(re.findall(r'(ë¶€ì¡±|ëª»|ì•ˆ|ë¬¸ì œ|ë¯¸í¡)', text)) / max(1, len(text.split()))
        
        # ê°ì • ì ìˆ˜ ê³„ì‚°
        sentiment_score = 50 + (positive_ratio * 300) - (negative_ratio * 400)
        sentiment_score = max(0, min(100, sentiment_score))
        
        # ì˜ë„ ë¶„ë¥˜
        if positive_ratio > 0.1:
            intent = "positive_evaluation"
        elif negative_ratio > 0.1:
            intent = "constructive_criticism"
        else:
            intent = "neutral_observation"
        
        # ì‹ ë¢°ë„ëŠ” í…ìŠ¤íŠ¸ ê¸¸ì´ì™€ ëª…í™•ì„±ì— ê¸°ë°˜
        confidence = min(80 + (text_length / 50), 95)
        
        return {
            "score": sentiment_score,
            "confidence": confidence,
            "sentiment": "positive" if sentiment_score > 65 else "negative" if sentiment_score < 35 else "neutral",
            "intent": intent,
            "aspect_scores": {aspect: sentiment_score + np.random.randint(-10, 10) 
                            for aspect in self.framework[dimension].get("bert_aspects", [])}
        }
    
    def comprehensive_analysis(self, uid: str, opinion: str) -> Dict[str, Any]:
        """ì „ì²´ 8ëŒ€ ì˜ì—­ ì¢…í•© ë¶„ì„ - í¸í–¥ ê²€ì‚¬ í¬í•¨"""
        dimension_results = {}
        dimension_scores = {}
        
        # ê° ì˜ì—­ë³„ ë¶„ì„
        for dimension in self.framework.keys():
            result = self.analyze_text(opinion, dimension)
            dimension_results[dimension] = result
            dimension_scores[dimension] = result["score"]
        
        # í¸í–¥ì„± ê²€ì‚¬
        bias_check = self.bias_detector.check_text_bias(opinion)
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        overall_result = self.calculate_overall_score(dimension_scores)
        
        # ì„±ê³¼ ì˜ˆì¸¡ (ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜)
        performance_prediction = self._predict_performance(dimension_scores)
        
        return {
            "text_analysis": {
                "overall_score": overall_result["overall_score"],
                "grade": overall_result["grade"],
                "grade_description": overall_result["grade_description"],
                "percentile": overall_result["percentile"],
                "dimension_scores": dimension_scores,
                "dimension_details": dimension_results,
                "top_strengths": self._identify_strengths(dimension_scores),
                "improvement_areas": self._identify_improvements(dimension_scores)
            },
            "bias_analysis": bias_check,
            "performance_prediction": performance_prediction,
            "quantitative_analysis": {
                "quantitative_score": 50,
                "confidence": 0,
                "data_quality": "ì—†ìŒ",
                "data_count": 0
            },
            "hybrid_analysis": overall_result,
            "analysis_metadata": {
                "uid": uid,
                "analysis_version": "AIRISS v4.1 - Deep Learning Enhanced",
                "analysis_timestamp": datetime.now().isoformat(),
                "models_used": ["enhanced_keyword", "bert_simulation", "bias_detector"]
            }
        }
    
    def _identify_strengths(self, dimension_scores: Dict[str, float]) -> List[Dict[str, Any]]:
        """ìƒìœ„ 3ê°œ ê°•ì  ì˜ì—­ ì‹ë³„"""
        sorted_dims = sorted(dimension_scores.items(), key=lambda x: x[1], reverse=True)[:3]
        return [
            {
                "dimension": dim,
                "score": score,
                "description": self.framework[dim]["description"]
            }
            for dim, score in sorted_dims if score >= 70
        ]
    
    def _identify_improvements(self, dimension_scores: Dict[str, float]) -> List[Dict[str, Any]]:
        """í•˜ìœ„ 3ê°œ ê°œì„  ì˜ì—­ ì‹ë³„"""
        sorted_dims = sorted(dimension_scores.items(), key=lambda x: x[1])[:3]
        return [
            {
                "dimension": dim,
                "score": score,
                "description": self.framework[dim]["description"],
                "recommendation": self._get_improvement_recommendation(dim)
            }
            for dim, score in sorted_dims if score < 70
        ]
    
    def _get_improvement_recommendation(self, dimension: str) -> str:
        """ì˜ì—­ë³„ ê°œì„  ê¶Œê³ ì‚¬í•­"""
        recommendations = {
            "ì—…ë¬´ì„±ê³¼": "ëª©í‘œ ì„¤ì •ì„ êµ¬ì²´í™”í•˜ê³ , ì£¼ê°„ ì„±ê³¼ ë¦¬ë·°ë¥¼ í†µí•´ ì§„ì²™ë„ë¥¼ ê´€ë¦¬í•˜ì„¸ìš”.",
            "KPIë‹¬ì„±": "í•µì‹¬ ì§€í‘œì— ì§‘ì¤‘í•˜ê³ , ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì„ ê°•í™”í•˜ì„¸ìš”.",
            "íƒœë„ë§ˆì¸ë“œ": "ê¸ì •ì  í”¼ë“œë°± ë¬¸í™”ë¥¼ ì¡°ì„±í•˜ê³ , ì„±ì¥ ë§ˆì¸ë“œì…‹ ì›Œí¬ìƒµ ì°¸ì—¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.",
            "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜": "ì ê·¹ì  ê²½ì²­ ìŠ¤í‚¬ì„ ê°œë°œí•˜ê³ , ëª…í™•í•œ ë¬¸ì„œ ì‘ì„± êµìœ¡ì„ ë°›ìœ¼ì„¸ìš”.",
            "ë¦¬ë”ì‹­í˜‘ì—…": "íŒ€ ë¹Œë”© í™œë™ì— ì°¸ì—¬í•˜ê³ , ë©˜í† ë§ í”„ë¡œê·¸ë¨ì„ í™œìš©í•˜ì„¸ìš”.",
            "ì „ë¬¸ì„±í•™ìŠµ": "ê´€ë ¨ ë¶„ì•¼ ì˜¨ë¼ì¸ ê°•ì˜ë¥¼ ìˆ˜ê°•í•˜ê³ , ì „ë¬¸ ìê²©ì¦ ì·¨ë“ì„ ê³ ë ¤í•˜ì„¸ìš”.",
            "ì°½ì˜í˜ì‹ ": "ì•„ì´ë””ì–´ ë¸Œë ˆì¸ìŠ¤í† ë° ì„¸ì…˜ì— ì°¸ì—¬í•˜ê³ , íƒ€ ë¶€ì„œ ë²¤ì¹˜ë§ˆí‚¹ì„ ì‹œë„í•˜ì„¸ìš”.",
            "ì¡°ì§ì ì‘": "íšŒì‚¬ ë¬¸í™” ì´í•´ë„ë¥¼ ë†’ì´ê³ , ì‚¬ë‚´ ë„¤íŠ¸ì›Œí‚¹ì„ ê°•í™”í•˜ì„¸ìš”."
        }
        return recommendations.get(dimension, "ì§€ì†ì ì¸ ìê¸°ê³„ë°œê³¼ í”¼ë“œë°± ìˆ˜ìš© ìì„¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    def _predict_performance(self, dimension_scores: Dict[str, float]) -> Dict[str, Any]:
        """ê°„ë‹¨í•œ ì„±ê³¼ ì˜ˆì¸¡ ëª¨ë¸"""
        avg_score = sum(dimension_scores.values()) / len(dimension_scores)
        
        # ì„±ê³¼ íŠ¸ë Œë“œ ì˜ˆì¸¡
        if avg_score >= 85:
            trend = "ìƒìŠ¹"
            probability = 0.85
        elif avg_score >= 70:
            trend = "ìœ ì§€"
            probability = 0.70
        else:
            trend = "ì£¼ì˜í•„ìš”"
            probability = 0.60
        
        # ì´ì§ ìœ„í—˜ë„ (ì—­ì‚°)
        turnover_risk = max(0, min(100, 100 - avg_score))
        
        return {
            "6month_trend": trend,
            "success_probability": probability,
            "turnover_risk_score": round(turnover_risk, 1),
            "promotion_readiness": "ë†’ìŒ" if avg_score >= 85 else "ë³´í†µ" if avg_score >= 70 else "ë‚®ìŒ",
            "development_priority": self._identify_improvements(dimension_scores)[0]["dimension"] if self._identify_improvements(dimension_scores) else None
        }
    
    def calculate_overall_score(self, dimension_scores: Dict[str, float]) -> Dict[str, Any]:
        """ê°€ì¤‘í‰ê· ìœ¼ë¡œ ì¢…í•© ì ìˆ˜ ê³„ì‚° - ê°œì„ ëœ ë“±ê¸‰ ì²´ê³„"""
        weighted_sum = 0
        total_weight = 0
        
        for dimension, score in dimension_scores.items():
            if dimension in self.framework:
                weight = self.framework[dimension]["weight"]
                weighted_sum += score * weight
                total_weight += weight
        
        overall_score = weighted_sum / total_weight if total_weight > 0 else 50
        
        # ê°œì„ ëœ ë“±ê¸‰ ì‚°ì • ì²´ê³„
        if overall_score >= 95:
            grade = "S"
            grade_desc = "íƒì›”í•¨ (Superb) - ì „ì‚¬ TOP 1%"
            percentile = "ìƒìœ„ 1%"
            badge = "ğŸ†"
        elif overall_score >= 90:
            grade = "A+"
            grade_desc = "ë§¤ìš° ìš°ìˆ˜ (Excellent) - ì „ì‚¬ TOP 5%"
            percentile = "ìƒìœ„ 5%"
            badge = "â­â­â­"
        elif overall_score >= 85:
            grade = "A"
            grade_desc = "ìš°ìˆ˜ (Outstanding) - ì „ì‚¬ TOP 10%"
            percentile = "ìƒìœ„ 10%"
            badge = "â­â­"
        elif overall_score >= 80:
            grade = "B+"
            grade_desc = "ì–‘í˜¸ (Good) - ì „ì‚¬ TOP 20%"
            percentile = "ìƒìœ„ 20%"
            badge = "â­"
        elif overall_score >= 75:
            grade = "B"
            grade_desc = "í‰ê·  ì´ìƒ (Above Average) - ì „ì‚¬ TOP 30%"
            percentile = "ìƒìœ„ 30%"
            badge = "âœ¨"
        elif overall_score >= 70:
            grade = "C+"
            grade_desc = "í‰ê·  (Average) - ì „ì‚¬ TOP 40%"
            percentile = "ìƒìœ„ 40%"
            badge = "ğŸ‘"
        elif overall_score >= 60:
            grade = "C"
            grade_desc = "ê°œì„  í•„ìš” (Needs Improvement) - ì „ì‚¬ TOP 60%"
            percentile = "ìƒìœ„ 60%"
            badge = "ğŸ“ˆ"
        else:
            grade = "D"
            grade_desc = "ì§‘ì¤‘ ê´€ë¦¬ í•„ìš” (Requires Attention) - í•˜ìœ„ 40%"
            percentile = "í•˜ìœ„ 40%"
            badge = "ğŸš¨"
        
        # ìƒì„¸ ë¶„ì„ ì¶”ê°€
        score_distribution = self._analyze_score_distribution(dimension_scores)
        
        return {
            "overall_score": round(overall_score, 1),
            "grade": grade,
            "grade_description": grade_desc,
            "percentile": percentile,
            "badge": badge,
            "confidence": self._calculate_confidence(dimension_scores),
            "score_distribution": score_distribution,
            "consistency": self._calculate_consistency(dimension_scores)
        }
    
    def _analyze_score_distribution(self, dimension_scores: Dict[str, float]) -> Dict[str, Any]:
        """ì ìˆ˜ ë¶„í¬ ë¶„ì„"""
        scores = list(dimension_scores.values())
        return {
            "mean": round(np.mean(scores), 1),
            "std": round(np.std(scores), 1),
            "min": round(min(scores), 1),
            "max": round(max(scores), 1),
            "range": round(max(scores) - min(scores), 1)
        }
    
    def _calculate_consistency(self, dimension_scores: Dict[str, float]) -> str:
        """ì¼ê´€ì„± í‰ê°€"""
        std = np.std(list(dimension_scores.values()))
        if std < 10:
            return "ë§¤ìš° ì¼ê´€ë¨"
        elif std < 20:
            return "ì¼ê´€ë¨"
        elif std < 30:
            return "ë‹¤ì†Œ ë¶ˆê· í˜•"
        else:
            return "ë¶ˆê· í˜•"
    
    def _calculate_confidence(self, dimension_scores: Dict[str, float]) -> float:
        """ì¢…í•© ì‹ ë¢°ë„ ê³„ì‚°"""
        # ì ìˆ˜ê°€ ê·¹ë‹¨ì ì´ì§€ ì•Šê³  ì¼ê´€ì„± ìˆì„ìˆ˜ë¡ ì‹ ë¢°ë„ ì¦ê°€
        scores = list(dimension_scores.values())
        std = np.std(scores)
        mean = np.mean(scores)
        
        # í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ì¦ê°€
        consistency_confidence = max(0, 100 - std * 2)
        
        # ê·¹ë‹¨ì  ì ìˆ˜ê°€ ì ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ì¦ê°€
        extreme_count = sum(1 for s in scores if s < 20 or s > 90)
        extreme_penalty = extreme_count * 10
        
        confidence = min(100, max(50, consistency_confidence - extreme_penalty))
        return round(confidence, 1)
    
    async def generate_ai_feedback(
        self,
        uid: str,
        opinion: str,
        api_key: str,
        model: str = "gpt-4",  # ì—…ê·¸ë ˆì´ë“œ
        max_tokens: int = 1500
    ) -> Dict[str, Any]:
        """OpenAIë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ AI í”¼ë“œë°± ìƒì„±"""
        
        if not self.openai_available:
            return {
                "ai_strengths": "OpenAI ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "ai_weaknesses": "pip install openaië¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.",
                "ai_feedback": "ë”¥ëŸ¬ë‹ ê¸°ë°˜ ë¶„ì„ë§Œ ì œê³µë©ë‹ˆë‹¤.",
                "ai_recommendations": [],
                "error": "OpenAI ëª¨ë“ˆ ë¯¸ì„¤ì¹˜"
            }
        
        if not api_key:
            return {
                "ai_strengths": "API í‚¤ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "ai_weaknesses": "OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.",
                "ai_feedback": "ë”¥ëŸ¬ë‹ ê¸°ë°˜ ë¶„ì„ë§Œ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "ai_recommendations": [],
                "error": "API í‚¤ ì—†ìŒ"
            }
        
        try:
            client = self.openai.OpenAI(api_key=api_key)
            
            # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸
            prompt = f"""
ì§ì› {uid}ì˜ í‰ê°€ ì˜ê²¬ì„ AIRISS 8ëŒ€ ì˜ì—­ ê¸°ë°˜ìœ¼ë¡œ ì‹¬ì¸µ ë¶„ì„í•˜ì„¸ìš”:

í‰ê°€ ì˜ê²¬: {opinion[:1500]}

8ëŒ€ ì˜ì—­:
1. ì—…ë¬´ì„±ê³¼ (25%) - ì—…ë¬´ í’ˆì§ˆ, ìƒì‚°ì„±, ëª©í‘œ ë‹¬ì„±
2. KPIë‹¬ì„± (20%) - ì •ëŸ‰ì  ì„±ê³¼, ì§€í‘œ ë‹¬ì„±ë¥ 
3. íƒœë„ë§ˆì¸ë“œ (15%) - ì ê·¹ì„±, ì±…ì„ê°, ì„±ì¥ ì˜ì§€
4. ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ (15%) - ì†Œí†µ ëŠ¥ë ¥, í˜‘ë ¥ì  ëŒ€í™”
5. ë¦¬ë”ì‹­í˜‘ì—… (10%) - íŒ€ì›Œí¬, ë¦¬ë”ì‹­, ì˜í–¥ë ¥
6. ì „ë¬¸ì„±í•™ìŠµ (8%) - ê¸°ìˆ  ì—­ëŸ‰, í•™ìŠµ ì†ë„
7. ì°½ì˜í˜ì‹  (5%) - ì°½ì˜ì„±, ë³€í™” ì£¼ë„
8. ì¡°ì§ì ì‘ (2%) - ì¡°ì§ ë¬¸í™” ì ì‘, ìœ¤ë¦¬ì„±

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”:

[í•µì‹¬ ê°•ì ] (3ê°€ì§€)
- ê°•ì 1: (ì˜ì—­ëª…) êµ¬ì²´ì  í–‰ë™/ì„±ê³¼
- ê°•ì 2: (ì˜ì—­ëª…) êµ¬ì²´ì  í–‰ë™/ì„±ê³¼
- ê°•ì 3: (ì˜ì—­ëª…) êµ¬ì²´ì  í–‰ë™/ì„±ê³¼

[ê°œì„  í•„ìš”ì‚¬í•­] (3ê°€ì§€)
- ê°œì„ 1: (ì˜ì—­ëª…) êµ¬ì²´ì  ê°œì„ ì 
- ê°œì„ 2: (ì˜ì—­ëª…) êµ¬ì²´ì  ê°œì„ ì 
- ê°œì„ 3: (ì˜ì—­ëª…) êµ¬ì²´ì  ê°œì„ ì 

[ì¢…í•© í”¼ë“œë°±]
- í˜„ì¬ ìˆ˜ì¤€: (1-2ë¬¸ì¥)
- ì„±ì¥ ì ì¬ë ¥: (1-2ë¬¸ì¥)
- í•µì‹¬ ì œì–¸: (1-2ë¬¸ì¥)

[êµ¬ì²´ì  ì‹¤í–‰ ê³„íš] (3ê°€ì§€)
1. ë‹¨ê¸°(1ê°œì›”): êµ¬ì²´ì  ì•¡ì…˜
2. ì¤‘ê¸°(3ê°œì›”): êµ¬ì²´ì  ëª©í‘œ
3. ì¥ê¸°(6ê°œì›”): ê¸°ëŒ€ ì„±ê³¼
"""
            
            response = await asyncio.to_thread(
                client.chat.completions.create,
                model=model,
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ OKê¸ˆìœµê·¸ë£¹ì˜ ìˆ˜ì„ HR ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê±´ì„¤ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”."
                    },
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=0.7
            )
            
            feedback = response.choices[0].message.content
            
            # ì‘ë‹µ íŒŒì‹± ê°œì„ 
            sections = {
                "strengths": "",
                "weaknesses": "",
                "overall": "",
                "action_plan": []
            }
            
            if "[í•µì‹¬ ê°•ì ]" in feedback:
                parts = feedback.split("[í•µì‹¬ ê°•ì ]")[1].split("[ê°œì„  í•„ìš”ì‚¬í•­]")
                sections["strengths"] = parts[0].strip() if len(parts) > 0 else ""
                
                if len(parts) > 1:
                    parts2 = parts[1].split("[ì¢…í•© í”¼ë“œë°±]")
                    sections["weaknesses"] = parts2[0].strip() if len(parts2) > 0 else ""
                    
                    if len(parts2) > 1:
                        parts3 = parts2[1].split("[êµ¬ì²´ì  ì‹¤í–‰ ê³„íš]")
                        sections["overall"] = parts3[0].strip() if len(parts3) > 0 else ""
                        
                        if len(parts3) > 1:
                            action_items = parts3[1].strip().split('\n')
                            sections["action_plan"] = [item.strip() for item in action_items if item.strip()]
            
            return {
                "ai_strengths": sections["strengths"],
                "ai_weaknesses": sections["weaknesses"],
                "ai_feedback": sections["overall"],
                "ai_recommendations": sections["action_plan"],
                "error": None
            }
            
        except Exception as e:
            logger.error(f"OpenAI API ì˜¤ë¥˜: {e}")
            return {
                "ai_strengths": f"AI ë¶„ì„ ì˜¤ë¥˜: {str(e)}",
                "ai_weaknesses": "AI ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "ai_feedback": f"ì˜¤ë¥˜: {str(e)}",
                "ai_recommendations": [],
                "error": str(e)
            }


class BiasDetector:
    """í¸í–¥ì„± íƒì§€ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.bias_patterns = {
            "gender": {
                "male_terms": ["ê·¸", "ë‚¨ì", "ë‚¨ì„±", "ì•„ë“¤", "ì•„ë²„ì§€"],
                "female_terms": ["ê·¸ë…€", "ì—¬ì", "ì—¬ì„±", "ë”¸", "ì–´ë¨¸ë‹ˆ"]
            },
            "age": {
                "young_terms": ["ì Šì€", "ì‹ ì…", "ì£¼ë‹ˆì–´", "ë°€ë ˆë‹ˆì–¼", "Zì„¸ëŒ€"],
                "old_terms": ["ë‚˜ì´ë“ ", "ì‹œë‹ˆì–´", "ë² í…Œë‘", "ê³ ë ¹", "ì—°ì¥ì"]
            },
            "appearance": {
                "terms": ["ì™¸ëª¨", "í‚¤", "ëª¸ë¬´ê²Œ", "ì˜ìƒê¸´", "ì˜ˆìœ", "ëš±ëš±í•œ", "ë§ˆë¥¸"]
            }
        }
    
    def check_text_bias(self, text: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ì˜ í¸í–¥ì„± ê²€ì‚¬"""
        text_lower = text.lower()
        bias_flags = {
            "gender_bias": False,
            "age_bias": False,
            "appearance_bias": False,
            "bias_score": 0,
            "bias_details": []
        }
        
        # ì„±ë³„ í¸í–¥ ê²€ì‚¬
        male_count = sum(1 for term in self.bias_patterns["gender"]["male_terms"] if term in text_lower)
        female_count = sum(1 for term in self.bias_patterns["gender"]["female_terms"] if term in text_lower)
        
        if abs(male_count - female_count) > 2:
            bias_flags["gender_bias"] = True
            bias_flags["bias_details"].append({
                "type": "gender",
                "severity": "medium",
                "description": "ì„±ë³„ ê´€ë ¨ ìš©ì–´ê°€ í¸í–¥ì ìœ¼ë¡œ ì‚¬ìš©ë¨"
            })
            bias_flags["bias_score"] += 30
        
        # ì—°ë ¹ í¸í–¥ ê²€ì‚¬
        young_count = sum(1 for term in self.bias_patterns["age"]["young_terms"] if term in text_lower)
        old_count = sum(1 for term in self.bias_patterns["age"]["old_terms"] if term in text_lower)
        
        if young_count > 0 or old_count > 0:
            bias_flags["age_bias"] = True
            bias_flags["bias_details"].append({
                "type": "age",
                "severity": "low",
                "description": "ì—°ë ¹ ê´€ë ¨ ìš©ì–´ê°€ ì‚¬ìš©ë¨"
            })
            bias_flags["bias_score"] += 20
        
        # ì™¸ëª¨ í¸í–¥ ê²€ì‚¬
        appearance_count = sum(1 for term in self.bias_patterns["appearance"]["terms"] if term in text_lower)
        
        if appearance_count > 0:
            bias_flags["appearance_bias"] = True
            bias_flags["bias_details"].append({
                "type": "appearance",
                "severity": "high",
                "description": "ì™¸ëª¨ ê´€ë ¨ ë¶€ì ì ˆí•œ ì–¸ê¸‰ì´ í¬í•¨ë¨"
            })
            bias_flags["bias_score"] += 50
        
        # ì „ë°˜ì  ê³µì •ì„± ì ìˆ˜
        bias_flags["fairness_score"] = 100 - bias_flags["bias_score"]
        bias_flags["is_fair"] = bias_flags["fairness_score"] >= 80
        
        return bias_flags