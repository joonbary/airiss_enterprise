# app/api/upload.py
# AIRISS v4.0 íŒŒì¼ ì—…ë¡œë“œ API - SQLiteService ë©”ì„œë“œ í˜¸ì¶œ ì˜¤ë¥˜ ì™„ì „ í•´ê²° ë²„ì „
# async/await ì²˜ë¦¬ + ì˜¬ë°”ë¥¸ ì¸ì ì „ë‹¬

from fastapi import APIRouter, UploadFile, File, HTTPException, Depends
from fastapi.responses import JSONResponse
import pandas as pd
import io
import uuid
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional
import traceback

# í”„ë¡œì íŠ¸ ë‚´ ëª¨ë“ˆ import
from app.db.sqlite_service import SQLiteService
from app.schemas.schemas import FileUploadResponse, FileInfoResponse

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ì—…ë¡œë“œ ë¼ìš°í„° ìƒì„±
router = APIRouter(prefix="/upload", tags=["upload"])

# SQLiteService ì˜ì¡´ì„± ì£¼ì…
def get_sqlite_service() -> SQLiteService:
    service = SQLiteService()
    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ê²ƒì€ ë¬¸ì œê°€ ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
    # ì‹¤ì œ ì‚¬ìš© ì‹œì ì—ì„œ ì´ˆê¸°í™”í•˜ë„ë¡ ë³€ê²½
    return service

@router.post("/upload/", response_model=FileUploadResponse)
async def upload_file(
    file: UploadFile = File(...),
    db_service: SQLiteService = Depends(get_sqlite_service)
):
    """
    íŒŒì¼ ì—…ë¡œë“œ ë° AIRISS v4.0 í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬
    - Excel (.xlsx, .xls) ë° CSV íŒŒì¼ ì§€ì›
    - í…ìŠ¤íŠ¸ + ì •ëŸ‰ë°ì´í„° ìë™ ê°ì§€
    - SQLiteService DB í†µí•© ì €ì¥
    """
    
    file_id = None
    try:
        # ğŸ”¥ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ì‹¤í–‰)
        try:
            await db_service.init_database()
        except Exception as e:
            logger.warning(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ê±´ë„ˆëœ€ (ì´ë¯¸ ì´ˆê¸°í™”ë¨): {e}")
        
        # íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
        if not file.filename:
            raise HTTPException(status_code=400, detail="íŒŒì¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤")
        
        # ì§€ì›ë˜ëŠ” íŒŒì¼ í˜•ì‹ í™•ì¸
        supported_extensions = ['.csv', '.xlsx', '.xls']
        file_extension = None
        for ext in supported_extensions:
            if file.filename.lower().endswith(ext):
                file_extension = ext
                break
        
        if not file_extension:
            raise HTTPException(
                status_code=400, 
                detail=f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(supported_extensions)}"
            )
        
        logger.info(f"ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘: {file.filename} ({file_extension})")
        
        # íŒŒì¼ ë‚´ìš© ì½ê¸°
        try:
            file_contents = await file.read()
            if len(file_contents) == 0:
                raise HTTPException(status_code=400, detail="ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤")
            
            logger.info(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {len(file_contents)} bytes")
            
        except Exception as e:
            logger.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            raise HTTPException(status_code=400, detail=f"íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
        
        # DataFrame ìƒì„±
        df = None
        try:
            if file_extension in ['.xlsx', '.xls']:
                # Excel íŒŒì¼ ì²˜ë¦¬
                df = pd.read_excel(io.BytesIO(file_contents))
                logger.info("âœ… Excel íŒŒì¼ íŒŒì‹± ì™„ë£Œ")
                
            elif file_extension == '.csv':
                # CSV íŒŒì¼ ì²˜ë¦¬ (ë‹¤ì¤‘ ì¸ì½”ë”© ì‹œë„)
                encodings = ['utf-8', 'cp949', 'euc-kr', 'iso-8859-1', 'latin1']
                
                for encoding in encodings:
                    try:
                        df = pd.read_csv(io.StringIO(file_contents.decode(encoding)))
                        logger.info(f"âœ… CSV íŒŒì¼ íŒŒì‹± ì™„ë£Œ (ì¸ì½”ë”©: {encoding})")
                        break
                    except (UnicodeDecodeError, UnicodeError):
                        continue
                    except Exception as e:
                        logger.warning(f"CSV íŒŒì‹± ì‹œë„ ì‹¤íŒ¨ ({encoding}): {str(e)}")
                        continue
                
                if df is None:
                    raise HTTPException(
                        status_code=400, 
                        detail="CSV íŒŒì¼ ì¸ì½”ë”©ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. UTF-8, CP949, EUC-KR ì¸ì½”ë”©ì„ ì§€ì›í•©ë‹ˆë‹¤."
                    )
        
        except Exception as e:
            logger.error(f"DataFrame ìƒì„± ì˜¤ë¥˜: {str(e)}")
            raise HTTPException(status_code=400, detail=f"íŒŒì¼ í˜•ì‹ì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
        
        # DataFrame ê¸°ë³¸ ê²€ì¦
        if df is None:
            raise HTTPException(status_code=400, detail="DataFrame ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
        
        if df.empty:
            raise HTTPException(status_code=400, detail="íŒŒì¼ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        if len(df.columns) == 0:
            raise HTTPException(status_code=400, detail="íŒŒì¼ì— ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤")
        
        # ğŸ”¥ ì•ˆì „í•œ ì»¬ëŸ¼ ì •ë³´ ì¶”ì¶œ
        try:
            # ì»¬ëŸ¼ëª…ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            all_columns = [str(col).strip() for col in df.columns.tolist()]
            
            # ë¹ˆ ì»¬ëŸ¼ëª… ì œê±°
            all_columns = [col for col in all_columns if col and col != 'nan' and col != 'None']
            
            if not all_columns:
                raise HTTPException(status_code=400, detail="ìœ íš¨í•œ ì»¬ëŸ¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤")
            
            logger.info(f"ğŸ“‹ ì¶”ì¶œëœ ì»¬ëŸ¼: {all_columns}")
            
        except Exception as e:
            logger.error(f"ì»¬ëŸ¼ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
            raise HTTPException(status_code=400, detail=f"ì»¬ëŸ¼ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
        
        # AIRISS v4.0 ì»¬ëŸ¼ ë¶„ë¥˜ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        try:
            # UID ì»¬ëŸ¼ ì°¾ê¸°
            uid_columns = []
            uid_keywords = ['uid', 'id', 'ì•„ì´ë””', 'ì‚¬ë²ˆ', 'ì§ì›', 'user', 'emp', 'ì‚¬ìš©ì']
            for col in all_columns:
                col_lower = col.lower()
                if any(keyword in col_lower for keyword in uid_keywords):
                    uid_columns.append(col)
            
            # ì˜ê²¬/í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì°¾ê¸°  
            opinion_columns = []
            opinion_keywords = ['ì˜ê²¬', 'opinion', 'í‰ê°€', 'feedback', 'ë‚´ìš©', 'ì½”ë©˜íŠ¸', 'í”¼ë“œë°±', 'comment', 'review', 'ì„¤ëª…']
            for col in all_columns:
                col_lower = col.lower()
                if any(keyword in col_lower for keyword in opinion_keywords):
                    opinion_columns.append(col)
            
            # ğŸ†• ì •ëŸ‰ë°ì´í„° ì»¬ëŸ¼ ì°¾ê¸° (AIRISS v4.0 í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ìš©)
            quantitative_columns = []
            quant_keywords = ['ì ìˆ˜', 'score', 'í‰ì ', 'rating', 'ë“±ê¸‰', 'grade', 'level', 
                            'ë‹¬ì„±ë¥ ', 'ë¹„ìœ¨', 'rate', '%', 'percent', 'íšŸìˆ˜', 'ê±´ìˆ˜', 'count']
            
            for col in all_columns:
                col_lower = col.lower()
                if any(keyword in col_lower for keyword in quant_keywords):
                    # ì‹¤ì œ ë°ì´í„°ê°€ ì •ëŸ‰ì ì¸ì§€ ìƒ˜í”Œ ê²€ì¦
                    try:
                        sample_data = df[col].dropna().head(10)
                        if len(sample_data) > 0:
                            quantitative_score = 0
                            for value in sample_data:
                                str_val = str(value).strip()
                                # ìˆ«ì, ë“±ê¸‰, í¼ì„¼íŠ¸ íŒ¨í„´ í™•ì¸
                                if (str_val.replace('.', '').replace('%', '').replace('ì ', '').replace('-', '').isdigit() or
                                    any(grade in str_val.upper() for grade in ['A', 'B', 'C', 'D', 'S', 'F']) or
                                    any(grade in str_val for grade in ['ìš°ìˆ˜', 'ì–‘í˜¸', 'ë³´í†µ', 'ë¯¸í¡', 'ë¶€ì¡±']) or
                                    any(grade in str_val for grade in ['1', '2', '3', '4', '5'])):
                                    quantitative_score += 1
                            
                            # ìƒ˜í”Œì˜ 70% ì´ìƒì´ ì •ëŸ‰ì ì´ë©´ ì •ëŸ‰ ì»¬ëŸ¼ìœ¼ë¡œ ë¶„ë¥˜
                            if len(sample_data) > 0 and (quantitative_score / len(sample_data)) >= 0.7:
                                quantitative_columns.append(col)
                    except Exception as e:
                        logger.warning(f"ì •ëŸ‰ ì»¬ëŸ¼ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ({col}): {str(e)}")
                        continue
            
            logger.info(f"ğŸ” UID ì»¬ëŸ¼: {uid_columns}")
            logger.info(f"ğŸ’¬ ì˜ê²¬ ì»¬ëŸ¼: {opinion_columns}")
            logger.info(f"ğŸ“Š ì •ëŸ‰ ì»¬ëŸ¼: {quantitative_columns}")
            
        except Exception as e:
            logger.error(f"ì»¬ëŸ¼ ë¶„ë¥˜ ì˜¤ë¥˜: {str(e)}")
            raise HTTPException(status_code=400, detail=f"ì»¬ëŸ¼ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        
        # ğŸ“Š ë°ì´í„° í’ˆì§ˆ ë¶„ì„
        try:
            total_records = len(df)
            
            # ì˜ê²¬ ì»¬ëŸ¼ ê¸°ì¤€ ë¹„ì–´ìˆì§€ ì•Šì€ ë ˆì½”ë“œ ìˆ˜
            text_non_empty = 0
            if opinion_columns:
                text_non_empty = len(df.dropna(subset=opinion_columns))
            
            # ì •ëŸ‰ ì»¬ëŸ¼ ê¸°ì¤€ ë¹„ì–´ìˆì§€ ì•Šì€ ë ˆì½”ë“œ ìˆ˜
            quant_non_empty = 0
            if quantitative_columns:
                quant_non_empty = len(df.dropna(subset=quantitative_columns))
            
            # ë°ì´í„° í’ˆì§ˆ ì ìˆ˜
            text_completeness = round((text_non_empty / total_records) * 100, 1) if total_records > 0 else 0
            quant_completeness = round((quant_non_empty / total_records) * 100, 1) if total_records > 0 else 0
            
            # AIRISS ë¶„ì„ ì¤€ë¹„ë„ í‰ê°€
            airiss_ready = len(uid_columns) > 0 and len(opinion_columns) > 0
            hybrid_ready = len(quantitative_columns) > 0
            
            logger.info(f"ğŸ“ˆ ë°ì´í„° í’ˆì§ˆ: í…ìŠ¤íŠ¸ {text_completeness}%, ì •ëŸ‰ {quant_completeness}%")
            logger.info(f"ğŸ¯ ë¶„ì„ ì¤€ë¹„ë„: AIRISS={airiss_ready}, í•˜ì´ë¸Œë¦¬ë“œ={hybrid_ready}")
            
        except Exception as e:
            logger.error(f"ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            # í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨í•´ë„ ì—…ë¡œë“œëŠ” ê³„ì† ì§„í–‰
            total_records = len(df)
            text_completeness = 0
            quant_completeness = 0
            airiss_ready = False
            hybrid_ready = False
        
        # ğŸ—„ï¸ SQLiteServiceì— íŒŒì¼ ë°ì´í„° ì €ì¥ (ğŸ”¥ ìˆ˜ì •ëœ ë¶€ë¶„)
        try:
            # file_dataì— dataframeì„ í¬í•¨í•˜ì—¬ ì „ë‹¬
            file_data = {
                'dataframe': df,  # ğŸ”¥ í•µì‹¬: DataFrameì„ file_dataì— í¬í•¨
                'filename': file.filename,
                'file_size': len(file_contents),
                'upload_time': datetime.now(),
                'total_records': total_records,
                'column_count': len(all_columns),
                'columns': all_columns,
                'uid_columns': uid_columns,
                'opinion_columns': opinion_columns,
                'quantitative_columns': quantitative_columns,
                'text_completeness': text_completeness,
                'quant_completeness': quant_completeness,
                'airiss_ready': airiss_ready,
                'hybrid_ready': hybrid_ready,
                'file_extension': file_extension
            }
            
            # ğŸ”¥ ìˆ˜ì •ëœ í˜¸ì¶œ: await ì¶”ê°€ + file_dataë§Œ ì „ë‹¬
            file_id = await db_service.save_file(file_data)
            
            logger.info(f"ğŸ’¾ SQLiteService ì €ì¥ ì™„ë£Œ: {file_id}")
            
        except Exception as e:
            logger.error(f"SQLiteService ì €ì¥ ì˜¤ë¥˜: {str(e)}")
            logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            raise HTTPException(status_code=500, detail=f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        
        # âœ… ì„±ê³µ ì‘ë‹µ ìƒì„±
        response_data = {
            "id": file_id,
            "filename": file.filename,
            "total_records": total_records,
            "column_count": len(all_columns),
            "columns": all_columns,
            "uid_columns": uid_columns,
            "opinion_columns": opinion_columns,
            "quantitative_columns": quantitative_columns,
            "airiss_ready": airiss_ready,
            "hybrid_ready": hybrid_ready,
            "data_quality": {
                "text_completeness": text_completeness,
                "quant_completeness": quant_completeness,
                "total_records": total_records,
                "text_non_empty": text_non_empty,
                "quant_non_empty": quant_non_empty
            },
            "upload_time": datetime.now().isoformat(),
            "file_size": len(file_contents),
            "message": "AIRISS v4.0 í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ì„ ìœ„í•œ íŒŒì¼ ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"
        }
        
        logger.info(f"ğŸ‰ íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ: {file.filename} -> {file_id}")
        return FileUploadResponse(**response_data)
        
    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ
        raise
        
    except Exception as e:
        # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ì²˜ë¦¬
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        
        # ìƒì„±ëœ íŒŒì¼ IDê°€ ìˆìœ¼ë©´ ì •ë¦¬ ì‹œë„
        if file_id:
            try:
                await db_service.delete_file(file_id)
                logger.info(f"ğŸ—‘ï¸ ì‹¤íŒ¨í•œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ: {file_id}")
            except:
                pass
        
        raise HTTPException(
            status_code=500, 
            detail=f"íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.get("/upload/{file_id}", response_model=FileInfoResponse)
async def get_file_info(
    file_id: str,
    db_service: SQLiteService = Depends(get_sqlite_service)
):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´ ì¡°íšŒ
    - SQLiteServiceì—ì„œ íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
    - DataFrame ê¸°ë³¸ ì •ë³´ ì œê³µ
    """
    
    try:
        logger.info(f"ğŸ“‹ íŒŒì¼ ì •ë³´ ì¡°íšŒ ìš”ì²­: {file_id}")
        
        # ğŸ”¥ ìˆ˜ì •ëœ í˜¸ì¶œ: await ì¶”ê°€
        file_record = await db_service.get_file(file_id)
        
        if not file_record:
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # get_fileì—ì„œ ì´ë¯¸ dataframeì„ í¬í•¨í•´ì„œ ë°˜í™˜í•˜ë¯€ë¡œ ë³„ë„ ë¡œë“œ ë¶ˆí•„ìš”
        df = file_record.get('dataframe')
        
        if df is None:
            raise HTTPException(status_code=404, detail="íŒŒì¼ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì‹¤ì‹œê°„ ë°ì´í„° ìƒíƒœ í™•ì¸
        current_records = len(df)
        current_columns = len(df.columns)
        
        # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        response_data = {
            "id": file_id,
            "filename": file_record.get('filename', 'Unknown'),
            "total_records": current_records,
            "column_count": current_columns,
            "columns": [str(col) for col in df.columns.tolist()],
            "uid_columns": file_record.get('uid_columns', []),
            "opinion_columns": file_record.get('opinion_columns', []),
            "quantitative_columns": file_record.get('quantitative_columns', []),
            "upload_time": file_record.get('upload_time', datetime.now().isoformat()),
            "file_size": file_record.get('file_size', 0),
            "airiss_ready": file_record.get('airiss_ready', False),
            "hybrid_ready": file_record.get('hybrid_ready', False),
            "data_quality": {
                "text_completeness": file_record.get('text_completeness', 0),
                "quant_completeness": file_record.get('quant_completeness', 0),
                "total_records": current_records
            }
        }
        
        logger.info(f"âœ… íŒŒì¼ ì •ë³´ ì¡°íšŒ ì„±ê³µ: {file_id}")
        return FileInfoResponse(**response_data)
        
    except HTTPException:
        raise
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@router.delete("/upload/{file_id}")
async def delete_file(
    file_id: str,
    db_service: SQLiteService = Depends(get_sqlite_service)
):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ ì‚­ì œ
    - SQLiteServiceì—ì„œ íŒŒì¼ ë° DataFrame ë°ì´í„° ì™„ì „ ì‚­ì œ
    """
    
    try:
        logger.info(f"ğŸ—‘ï¸ íŒŒì¼ ì‚­ì œ ìš”ì²­: {file_id}")
        
        # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ğŸ”¥ await ì¶”ê°€)
        file_record = await db_service.get_file(file_id)
        if not file_record:
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # íŒŒì¼ ì‚­ì œ (ğŸ”¥ await ì¶”ê°€)
        success = await db_service.delete_file(file_id)
        
        if success:
            logger.info(f"âœ… íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {file_id}")
            return {"message": f"íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤", "file_id": file_id}
        else:
            raise HTTPException(status_code=500, detail="íŒŒì¼ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
        
    except HTTPException:
        raise
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ì‚­ì œ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@router.get("/files/")
async def list_files(
    db_service: SQLiteService = Depends(get_sqlite_service)
):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ ì¡°íšŒ
    - ëª¨ë“  ì—…ë¡œë“œëœ íŒŒì¼ì˜ ê¸°ë³¸ ì •ë³´ ì œê³µ
    """
    
    try:
        logger.info("ğŸ“‚ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ìš”ì²­")
        
        # ëª¨ë“  íŒŒì¼ ëª©ë¡ ì¡°íšŒ (ğŸ”¥ await ì¶”ê°€)
        files = await db_service.list_files()
        
        # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        file_list = []
        for file_record in files:
            file_info = {
                "id": file_record.get('id'),
                "filename": file_record.get('filename'),
                "total_records": file_record.get('total_records', 0),
                "upload_time": file_record.get('upload_time', ''),
                "airiss_ready": file_record.get('airiss_ready', False),
                "hybrid_ready": file_record.get('hybrid_ready', False)
            }
            file_list.append(file_info)
        
        logger.info(f"âœ… íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì™„ë£Œ: {len(file_list)}ê°œ íŒŒì¼")
        return {"files": file_list, "total_count": len(file_list)}
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
