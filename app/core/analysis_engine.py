# app/core/analysis_engine.py
# AIRISS v4.0 ì™„ì „í•œ ë¶„ì„ ì—”ì§„ - v3.0 ê¸°ëŠ¥ 100% ë³´ì¡´ + ê°•í™”

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, List, Union
import json
import logging
import re
import asyncio

logger = logging.getLogger(__name__)

# AIRISS 8ëŒ€ ì˜ì—­ ì™„ì „ ì„¤ê³„ (v3.0ê³¼ ë™ì¼í•˜ê²Œ ë³´ì¡´)
AIRISS_FRAMEWORK = {
    "ì—…ë¬´ì„±ê³¼": {
        "keywords": {
            "positive": [
                "ìš°ìˆ˜", "íƒì›”", "ë›°ì–´ë‚¨", "ì„±ê³¼", "ë‹¬ì„±", "ì™„ë£Œ", "ì„±ê³µ", "íš¨ìœ¨", "ìƒì‚°ì ", 
                "ëª©í‘œë‹¬ì„±", "ì´ˆê³¼ë‹¬ì„±", "í’ˆì§ˆ", "ì •í™•", "ì‹ ì†", "ì™„ë²½", "ì „ë¬¸ì ", "ì²´ê³„ì ",
                "ì„±ê³¼ê°€", "ê²°ê³¼ë¥¼", "ì‹¤ì ì´", "ì™„ì„±ë„", "ë§Œì¡±ë„"
            ],
            "negative": [
                "ë¶€ì¡±", "ë¯¸í¡", "ì§€ì—°", "ì‹¤íŒ¨", "ë¬¸ì œ", "ì˜¤ë¥˜", "ëŠ¦ìŒ", "ë¹„íš¨ìœ¨", 
                "ëª©í‘œë¯¸ë‹¬", "í’ˆì§ˆì €í•˜", "ë¶€ì •í™•", "ë¯¸ì™„ì„±", "ë¶€ì‹¤", "ê°œì„ ", "ë³´ì™„"
            ]
        },
        "weight": 0.25,
        "description": "ì—…ë¬´ ì‚°ì¶œë¬¼ì˜ ì–‘ê³¼ ì§ˆ",
        "color": "#FF5722",
        "icon": "ğŸ“Š"
    },
    "KPIë‹¬ì„±": {
        "keywords": {
            "positive": [
                "KPIë‹¬ì„±", "ì§€í‘œë‹¬ì„±", "ëª©í‘œì´ˆê³¼", "ì„±ê³¼ìš°ìˆ˜", "ì‹¤ì ìš°ìˆ˜", "ë§¤ì¶œì¦ê°€", 
                "íš¨ìœ¨í–¥ìƒ", "ìƒì‚°ì„±í–¥ìƒ", "ìˆ˜ì¹˜ë‹¬ì„±", "ì„±ì¥", "ê°œì„ ", "ë‹¬ì„±ë¥ ", "ì´ˆê³¼"
            ],
            "negative": [
                "KPIë¯¸ë‹¬", "ëª©í‘œë¯¸ë‹¬", "ì‹¤ì ë¶€ì§„", "ë§¤ì¶œê°ì†Œ", "íš¨ìœ¨ì €í•˜", 
                "ìƒì‚°ì„±ì €í•˜", "ìˆ˜ì¹˜ë¶€ì¡±", "í•˜ë½", "í‡´ë³´", "ë¯¸ë‹¬"
            ]
        },
        "weight": 0.20,
        "description": "í•µì‹¬ì„±ê³¼ì§€í‘œ ë‹¬ì„±ë„",
        "color": "#4A4A4A",
        "icon": "ğŸ¯"
    },
    "íƒœë„ë§ˆì¸ë“œ": {
        "keywords": {
            "positive": [
                "ì ê·¹ì ", "ê¸ì •ì ", "ì—´ì •", "ì„±ì‹¤", "ì±…ì„ê°", "ì§„ì·¨ì ", "í˜‘ì¡°ì ", 
                "ì„±ì¥ì§€í–¥", "í•™ìŠµì˜ì§€", "ë„ì „ì •ì‹ ", "ì£¼ì¸ì˜ì‹", "í—Œì‹ ", "ì—´ì‹¬íˆ", "ë…¸ë ¥"
            ],
            "negative": [
                "ì†Œê·¹ì ", "ë¶€ì •ì ", "ë¬´ê´€ì‹¬", "ë¶ˆì„±ì‹¤", "íšŒí”¼", "ëƒ‰ì†Œì ", 
                "ë¹„í˜‘ì¡°ì ", "ì•ˆì£¼", "í˜„ìƒìœ ì§€", "ìˆ˜ë™ì ", "íƒœë„", "ë§ˆì¸ë“œ"
            ]
        },
        "weight": 0.15,
        "description": "ì—…ë¬´ì— ëŒ€í•œ íƒœë„ì™€ ë§ˆì¸ë“œì…‹",
        "color": "#F89C26",
        "icon": "ğŸ§ "
    },
    "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜": {
        "keywords": {
            "positive": [
                "ëª…í™•", "ì •í™•", "ì‹ ì†", "ì¹œì ˆ", "ê²½ì²­", "ì†Œí†µ", "ì „ë‹¬", "ì´í•´", 
                "ì„¤ë“", "í˜‘ì˜", "ì¡°ìœ¨", "ê³µìœ ", "íˆ¬ëª…", "ê°œë°©ì ", "ì˜ì‚¬ì†Œí†µ", "ì›í™œ"
            ],
            "negative": [
                "ë¶ˆëª…í™•", "ì§€ì—°", "ë¬´ì‹œ", "ì˜¤í•´", "ë‹¨ì ˆ", "ì¹¨ë¬µ", "íšŒí”¼", 
                "ë…ë‹¨", "ì¼ë°©ì ", "íì‡„ì ", "ì†Œí†µë¶€ì¡±", "ì „ë‹¬ë ¥"
            ]
        },
        "weight": 0.15,
        "description": "ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ê³¼ ìŠ¤íƒ€ì¼",
        "color": "#B3B3B3",
        "icon": "ğŸ’¬"
    },
    "ë¦¬ë”ì‹­í˜‘ì—…": {
        "keywords": {
            "positive": [
                "ë¦¬ë”ì‹­", "íŒ€ì›Œí¬", "í˜‘ì—…", "ì§€ì›", "ë©˜í† ë§", "ë™ê¸°ë¶€ì—¬", "ì¡°ìœ¨", 
                "í™”í•©", "íŒ€ë¹Œë”©", "ìœ„ì„", "ì½”ì¹­", "ì˜í–¥ë ¥", "í˜‘ë ¥", "íŒ€í”Œë ˆì´"
            ],
            "negative": [
                "ë…ë‹¨", "ê°ˆë“±", "ë¹„í˜‘ì¡°", "ì†Œì™¸", "ë¶„ì—´", "ëŒ€ë¦½", "ì´ê¸°ì£¼ì˜", 
                "ë°©í•´", "ë¬´ê´€ì‹¬", "ê³ ë¦½", "ê°œì¸ì£¼ì˜"
            ]
        },
        "weight": 0.10,
        "description": "ë¦¬ë”ì‹­ê³¼ í˜‘ì—… ëŠ¥ë ¥",
        "color": "#FF8A50",
        "icon": "ğŸ‘¥"
    },
    "ì „ë¬¸ì„±í•™ìŠµ": {
        "keywords": {
            "positive": [
                "ì „ë¬¸", "ìˆ™ë ¨", "ê¸°ìˆ ", "ì§€ì‹", "í•™ìŠµ", "ë°œì „", "ì—­ëŸ‰", "ëŠ¥ë ¥", 
                "ì„±ì¥", "í–¥ìƒ", "ìŠµë“", "ê°œë°œ", "ì „ë¬¸ì„±", "ë…¸í•˜ìš°", "ìŠ¤í‚¬", "ê²½í—˜"
            ],
            "negative": [
                "ë¯¸ìˆ™", "ë¶€ì¡±", "ë‚™í›„", "ë¬´ì§€", "ì •ì²´", "í‡´ë³´", "ë¬´ëŠ¥ë ¥", 
                "ê¸°ì´ˆë¶€ì¡±", "ì—­ëŸ‰ë¶€ì¡±", "ì‹¤ë ¥ë¶€ì¡±"
            ]
        },
        "weight": 0.08,
        "description": "ì „ë¬¸ì„±ê³¼ í•™ìŠµëŠ¥ë ¥",
        "color": "#6A6A6A",
        "icon": "ğŸ“š"
    },
    "ì°½ì˜í˜ì‹ ": {
        "keywords": {
            "positive": [
                "ì°½ì˜", "í˜ì‹ ", "ì•„ì´ë””ì–´", "ê°œì„ ", "íš¨ìœ¨í™”", "ìµœì í™”", "ìƒˆë¡œìš´", 
                "ë„ì „", "ë³€í™”", "ë°œìƒ", "ì°½ì¡°", "í˜ì‹ ì ", "ë…ì°½ì ", "ì°½ì¡°ì "
            ],
            "negative": [
                "ë³´ìˆ˜ì ", "ê²½ì§", "í‹€ì—ë°•íŒ", "ë³€í™”ê±°ë¶€", "ê¸°ì¡´ë°©ì‹", "ê´€ìŠµì ", 
                "ê²½ì§ëœ", "ê³ ì •ì ", "ë³€í™”ì—†ì´"
            ]
        },
        "weight": 0.05,
        "description": "ì°½ì˜ì„±ê³¼ í˜ì‹  ë§ˆì¸ë“œ",
        "color": "#FFA726",
        "icon": "ğŸ’¡"
    },
    "ì¡°ì§ì ì‘": {
        "keywords": {
            "positive": [
                "ì ì‘", "ìœµí™”", "ì¡°í™”", "ë¬¸í™”", "ê·œì¹™ì¤€ìˆ˜", "ìœ¤ë¦¬", "ì‹ ë¢°", 
                "ì•ˆì •", "ì¼ê´€ì„±", "ì„±ì‹¤ì„±", "ì¡°ì§", "íšŒì‚¬", "íŒ€ì—"
            ],
            "negative": [
                "ë¶€ì ì‘", "ê°ˆë“±", "ìœ„ë°˜", "ë¹„ìœ¤ë¦¬", "ë¶ˆì‹ ", "ì¼íƒˆ", 
                "ë¬¸ì œí–‰ë™", "ê·œì •ìœ„ë°˜", "ì¡°ì§ê³¼"
            ]
        },
        "weight": 0.02,
        "description": "ì¡°ì§ë¬¸í™” ì ì‘ë„ì™€ ìœ¤ë¦¬ì„±",
        "color": "#9E9E9E",
        "icon": "ğŸ¢"
    }
}

class QuantitativeAnalyzer:
    """í‰ê°€ë“±ê¸‰, ì ìˆ˜ ë“± ì •ëŸ‰ë°ì´í„° ë¶„ì„ ì „ìš© í´ë˜ìŠ¤ (v3.0 ë™ì¼)"""
    
    def __init__(self):
        self.grade_mappings = self.setup_grade_mappings()
        self.score_weights = self.setup_score_weights()
        logger.info("âœ… ì •ëŸ‰ë°ì´í„° ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def setup_grade_mappings(self) -> Dict[str, Dict]:
        """ë‹¤ì–‘í•œ í‰ê°€ë“±ê¸‰ í˜•ì‹ì„ ì ìˆ˜ë¡œ ë³€í™˜í•˜ëŠ” ë§¤í•‘ í…Œì´ë¸”"""
        return {
            # 5ë‹¨ê³„ ë“±ê¸‰
            'S': 100, 'A': 85, 'B': 70, 'C': 55, 'D': 40,
            
            # ì˜ë¬¸ ë“±ê¸‰  
            'A+': 100, 'A': 95, 'A-': 90,
            'B+': 85, 'B': 80, 'B-': 75,
            'C+': 70, 'C': 65, 'C-': 60,
            'D+': 55, 'D': 50, 'D-': 45,
            'F': 30,
            
            # ìˆ«ì ë“±ê¸‰
            '1': 100, '2': 80, '3': 60, '4': 40, '5': 20,
            '1ê¸‰': 100, '2ê¸‰': 80, '3ê¸‰': 60, '4ê¸‰': 40, '5ê¸‰': 20,
            
            # í•œê¸€ ë“±ê¸‰
            'ìš°ìˆ˜': 90, 'ì–‘í˜¸': 75, 'ë³´í†µ': 60, 'ë¯¸í¡': 45, 'ë¶€ì¡±': 30,
            'ìµœìš°ìˆ˜': 100, 'ìƒ': 85, 'ì¤‘': 65, 'í•˜': 45,
            
            # ë°±ë¶„ìœ„/í¼ì„¼íŠ¸
            'ìƒìœ„10%': 95, 'ìƒìœ„20%': 85, 'ìƒìœ„30%': 75, 
            'ìƒìœ„50%': 65, 'í•˜ìœ„50%': 50, 'í•˜ìœ„30%': 35,
            
            # OKê¸ˆìœµê·¸ë£¹ ë§ì¶¤ ë“±ê¸‰
            'OKâ˜…â˜…â˜…': 100, 'OKâ˜…â˜…': 90, 'OKâ˜…': 80, 
            'OK A': 75, 'OK B+': 70, 'OK B': 65, 'OK C': 55, 'OK D': 40
        }
    
    def setup_score_weights(self) -> Dict[str, float]:
        """ì •ëŸ‰ ë°ì´í„° í•­ëª©ë³„ ê°€ì¤‘ì¹˜ ì„¤ì •"""
        return {
            'performance_grade': 0.30,    # ì„±ê³¼í‰ê°€ ë“±ê¸‰
            'kpi_score': 0.25,           # KPI ì ìˆ˜
            'competency_grade': 0.20,    # ì—­ëŸ‰í‰ê°€ ë“±ê¸‰  
            'attendance_score': 0.10,    # ê·¼íƒœì ìˆ˜
            'training_score': 0.10,      # êµìœ¡ì´ìˆ˜ ì ìˆ˜
            'certificate_score': 0.05    # ìê²©ì¦/ì¸ì¦ ì ìˆ˜
        }
    
    def extract_quantitative_data(self, row: pd.Series) -> Dict[str, Any]:
        """í–‰ ë°ì´í„°ì—ì„œ ì •ëŸ‰ì  ìš”ì†Œ ì¶”ì¶œ"""
        quant_data = {}
        
        for col_name, value in row.items():
            col_lower = str(col_name).lower()
            
            # ì ìˆ˜ ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
            if any(keyword in col_lower for keyword in ['ì ìˆ˜', 'score', 'í‰ì ', 'rating']):
                quant_data[f'score_{col_name}'] = self.normalize_score(value)
            
            # ë“±ê¸‰ ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°  
            elif any(keyword in col_lower for keyword in ['ë“±ê¸‰', 'grade', 'í‰ê°€', 'level']):
                quant_data[f'grade_{col_name}'] = self.convert_grade_to_score(value)
            
            # ë‹¬ì„±ë¥ /ë°±ë¶„ìœ¨ ê´€ë ¨
            elif any(keyword in col_lower for keyword in ['ë‹¬ì„±ë¥ ', 'ë¹„ìœ¨', 'rate', '%', 'percent']):
                quant_data[f'rate_{col_name}'] = self.normalize_percentage(value)
            
            # íšŸìˆ˜/ê±´ìˆ˜ ê´€ë ¨
            elif any(keyword in col_lower for keyword in ['íšŸìˆ˜', 'ê±´ìˆ˜', 'count', 'íšŒ', 'ë²ˆ']):
                quant_data[f'count_{col_name}'] = self.normalize_count(value)
                
        return quant_data
    
    def convert_grade_to_score(self, grade_value) -> float:
        """ë“±ê¸‰ì„ ì ìˆ˜ë¡œ ë³€í™˜"""
        if pd.isna(grade_value) or grade_value == '':
            return 50.0
        
        grade_str = str(grade_value).strip().upper()
        
        if grade_str in self.grade_mappings:
            return float(self.grade_mappings[grade_str])
        
        try:
            score = float(grade_str)
            if 0 <= score <= 100:
                return score
            elif 0 <= score <= 5:
                return (score - 1) * 25
            elif 0 <= score <= 10:
                return score * 10
        except ValueError:
            pass
        
        if 'ìš°ìˆ˜' in grade_str or 'excellent' in grade_str.lower():
            return 90.0
        elif 'ì–‘í˜¸' in grade_str or 'good' in grade_str.lower():
            return 75.0
        elif 'ë³´í†µ' in grade_str or 'average' in grade_str.lower():
            return 60.0
        elif 'ë¯¸í¡' in grade_str or 'poor' in grade_str.lower():
            return 45.0
        
        logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ë“±ê¸‰ í˜•ì‹: {grade_value}, ê¸°ë³¸ê°’ 50 ì ìš©")
        return 50.0
    
    def normalize_score(self, score_value) -> float:
        """ì ìˆ˜ ê°’ ì •ê·œí™” (0-100 ë²”ìœ„ë¡œ)"""
        if pd.isna(score_value) or score_value == '':
            return 50.0
        
        try:
            score = float(str(score_value).replace('%', '').replace('ì ', ''))
            
            if 0 <= score <= 1:
                return score * 100
            elif 0 <= score <= 5:
                return (score - 1) * 25
            elif 0 <= score <= 10:
                return score * 10
            elif 0 <= score <= 100:
                return score
            else:
                return max(0, min(100, score))
                
        except (ValueError, TypeError):
            logger.warning(f"ì ìˆ˜ ë³€í™˜ ì‹¤íŒ¨: {score_value}, ê¸°ë³¸ê°’ 50 ì ìš©")
            return 50.0
    
    def normalize_percentage(self, percent_value) -> float:
        """ë°±ë¶„ìœ¨ ì •ê·œí™”"""
        if pd.isna(percent_value) or percent_value == '':
            return 50.0
        
        try:
            percent_str = str(percent_value).replace('%', '').replace('í¼ì„¼íŠ¸', '')
            percent = float(percent_str)
            
            if 0 <= percent <= 1:
                return percent * 100
            elif 0 <= percent <= 100:
                return percent
            else:
                return max(0, min(100, percent))
                
        except (ValueError, TypeError):
            logger.warning(f"ë°±ë¶„ìœ¨ ë³€í™˜ ì‹¤íŒ¨: {percent_value}, ê¸°ë³¸ê°’ 50 ì ìš©")
            return 50.0
    
    def normalize_count(self, count_value) -> float:
        """íšŸìˆ˜/ê±´ìˆ˜ë¥¼ ì ìˆ˜ë¡œ ë³€í™˜ (ìƒëŒ€ì  í‰ê°€)"""
        if pd.isna(count_value) or count_value == '':
            return 50.0
        
        try:
            count = float(str(count_value).replace('íšŒ', '').replace('ê±´', '').replace('ë²ˆ', ''))
            
            if count <= 0:
                return 30.0
            elif count <= 2:
                return 50.0
            elif count <= 5:
                return 70.0
            elif count <= 10:
                return 85.0
            else:
                return 95.0
                
        except (ValueError, TypeError):
            logger.warning(f"íšŸìˆ˜ ë³€í™˜ ì‹¤íŒ¨: {count_value}, ê¸°ë³¸ê°’ 50 ì ìš©")
            return 50.0
    
    def calculate_quantitative_score(self, quant_data: Dict[str, float]) -> Dict[str, Any]:
        """ì •ëŸ‰ ë°ì´í„°ë“¤ì„ ì¢…í•©í•˜ì—¬ ìµœì¢… ì ìˆ˜ ê³„ì‚°"""
        if not quant_data:
            return {
                "quantitative_score": 50.0,
                "confidence": 0.0,
                "contributing_factors": {},
                "data_quality": "ì—†ìŒ"
            }
        
        total_score = 0.0
        total_weight = 0.0
        contributing_factors = {}
        
        for data_key, score in quant_data.items():
            if 'grade_' in data_key:
                weight = 0.4
            elif 'score_' in data_key:
                weight = 0.3
            elif 'rate_' in data_key:
                weight = 0.2
            else:
                weight = 0.1
            
            total_score += score * weight
            total_weight += weight
            contributing_factors[data_key] = {
                "score": round(score, 1),
                "weight": weight,
                "contribution": round(score * weight, 1)
            }
        
        if total_weight > 0:
            final_score = total_score / total_weight
            confidence = min(total_weight * 20, 100)
        else:
            final_score = 50.0
            confidence = 0.0
        
        data_count = len(quant_data)
        if data_count >= 5:
            data_quality = "ë†’ìŒ"
        elif data_count >= 3:
            data_quality = "ì¤‘ê°„"
        elif data_count >= 1:
            data_quality = "ë‚®ìŒ"
        else:
            data_quality = "ì—†ìŒ"
        
        return {
            "quantitative_score": round(final_score, 1),
            "confidence": round(confidence, 1),
            "contributing_factors": contributing_factors,
            "data_quality": data_quality,
            "data_count": data_count
        }

class AIRISSAnalyzer:
    """AIRISS í…ìŠ¤íŠ¸ ë¶„ì„ê¸° (v3.0 ë™ì¼)"""
    
    def __init__(self):
        self.framework = AIRISS_FRAMEWORK
        self.openai_available = False
        self.openai = None
        try:
            import openai
            self.openai = openai
            self.openai_available = True
            logger.info("âœ… OpenAI ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
        except ImportError:
            logger.warning("âš ï¸ OpenAI ëª¨ë“ˆ ì—†ìŒ - í‚¤ì›Œë“œ ë¶„ì„ë§Œ ê°€ëŠ¥")
    
    def analyze_text(self, text: str, dimension: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ë¶„ì„í•˜ì—¬ ì ìˆ˜ ì‚°ì¶œ"""
        if not text or text.lower() in ['nan', 'null', '', 'none']:
            return {"score": 50, "confidence": 0, "signals": {"positive": 0, "negative": 0, "positive_words": [], "negative_words": []}}
        
        keywords = self.framework[dimension]["keywords"]
        text_lower = text.lower()
        
        positive_matches = []
        negative_matches = []
        
        for word in keywords["positive"]:
            if word in text_lower:
                positive_matches.append(word)
        
        for word in keywords["negative"]:
            if word in text_lower:
                negative_matches.append(word)
        
        positive_count = len(positive_matches)
        negative_count = len(negative_matches)
        
        base_score = 50
        positive_boost = min(positive_count * 8, 45)
        negative_penalty = min(negative_count * 10, 40)
        
        text_length = len(text)
        if text_length > 50:
            length_bonus = min((text_length - 50) / 100 * 5, 10)
        else:
            length_bonus = 0
        
        final_score = base_score + positive_boost - negative_penalty + length_bonus
        final_score = max(10, min(100, final_score))
        
        total_signals = positive_count + negative_count
        base_confidence = min(total_signals * 12, 80)
        length_confidence = min(text_length / 20, 20)
        confidence = min(base_confidence + length_confidence, 100)
        
        return {
            "score": round(final_score, 1),
            "confidence": round(confidence, 1),
            "signals": {
                "positive": positive_count,
                "negative": negative_count,
                "positive_words": positive_matches[:5],
                "negative_words": negative_matches[:5]
            }
        }
    
    def calculate_overall_score(self, dimension_scores: Dict[str, float]) -> Dict[str, Any]:
        """ì¢…í•© ì ìˆ˜ ê³„ì‚°"""
        weighted_sum = 0
        total_weight = 0
        
        for dimension, score in dimension_scores.items():
            if dimension in self.framework:
                weight = self.framework[dimension]["weight"]
                weighted_sum += score * weight
                total_weight += weight
        
        overall_score = weighted_sum / total_weight if total_weight > 0 else 50
        
        if overall_score >= 95:
            grade = "OKâ˜…â˜…â˜…"
            grade_desc = "ìµœìš°ìˆ˜ ë“±ê¸‰ (TOP 1%)"
            percentile = "ìƒìœ„ 1%"
        elif overall_score >= 90:
            grade = "OKâ˜…â˜…"
            grade_desc = "ìš°ìˆ˜ ë“±ê¸‰ (TOP 5%)"
            percentile = "ìƒìœ„ 5%"
        elif overall_score >= 85:
            grade = "OKâ˜…"
            grade_desc = "ìš°ìˆ˜+ ë“±ê¸‰ (TOP 10%)"
            percentile = "ìƒìœ„ 10%"
        elif overall_score >= 80:
            grade = "OK A"
            grade_desc = "ì–‘í˜¸ ë“±ê¸‰ (TOP 20%)"
            percentile = "ìƒìœ„ 20%"
        elif overall_score >= 75:
            grade = "OK B+"
            grade_desc = "ì–‘í˜¸- ë“±ê¸‰ (TOP 30%)"
            percentile = "ìƒìœ„ 30%"
        elif overall_score >= 70:
            grade = "OK B"
            grade_desc = "ë³´í†µ ë“±ê¸‰ (TOP 40%)"
            percentile = "ìƒìœ„ 40%"
        elif overall_score >= 60:
            grade = "OK C"
            grade_desc = "ê°œì„ í•„ìš” ë“±ê¸‰ (TOP 60%)"
            percentile = "ìƒìœ„ 60%"
        else:
            grade = "OK D"
            grade_desc = "ì§‘ì¤‘ê°œì„  ë“±ê¸‰ (í•˜ìœ„ 40%)"
            percentile = "í•˜ìœ„ 40%"
        
        return {
            "overall_score": round(overall_score, 1),
            "grade": grade,
            "grade_description": grade_desc,
            "percentile": percentile,
            "weighted_scores": dimension_scores
        }
    
    async def generate_ai_feedback(self, uid: str, opinion: str, api_key: str = None, model: str = "gpt-3.5-turbo", max_tokens: int = 1200) -> Dict[str, Any]:
        """OpenAIë¥¼ ì‚¬ìš©í•œ ìƒì„¸ AI í”¼ë“œë°± ìƒì„±"""
        logger.info(f"AI í”¼ë“œë°± ìƒì„± ì‹œì‘: {uid}, API í‚¤ ì¡´ì¬: {bool(api_key)}, ëª¨ë¸: {model}")
        
        if not self.openai_available:
            logger.warning("OpenAI ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            return {
                "ai_strengths": "OpenAI ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "ai_weaknesses": "OpenAI ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "ai_feedback": "í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ë§Œ ì œê³µë©ë‹ˆë‹¤.",
                "processing_time": 0,
                "model_used": "none",
                "tokens_used": 0,
                "error": "OpenAI ëª¨ë“ˆ ë¯¸ì„¤ì¹˜"
            }
        
        if not api_key or api_key.strip() == "":
            return {
                "ai_strengths": "OpenAI API í‚¤ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "ai_weaknesses": "API í‚¤ë¥¼ ì…ë ¥í•˜ë©´ ìƒì„¸í•œ ê°œì„ ì  ë¶„ì„ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "ai_feedback": "í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ë§Œ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "processing_time": 0,
                "model_used": "none",
                "tokens_used": 0,
                "error": "API í‚¤ ì—†ìŒ"
            }
        
        start_time = datetime.now()
        
        try:
            client = self.openai.OpenAI(api_key=api_key.strip())
            
            prompt = self.create_airiss_prompt(uid, opinion, model, max_tokens)
            
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ AIRISS 8ëŒ€ ì˜ì—­ ê¸°ë°˜ ì „ë¬¸ HR ë¶„ì„ê°€ì…ë‹ˆë‹¤."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                max_tokens=max_tokens,
                temperature=0.7,
                timeout=30
            )
            
            feedback_text = response.choices[0].message.content.strip()
            strengths, weaknesses, complete_feedback = self.parse_ai_response(feedback_text)
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return {
                "ai_strengths": strengths,
                "ai_weaknesses": weaknesses,
                "ai_feedback": complete_feedback,
                "processing_time": round(processing_time, 2),
                "model_used": model,
                "tokens_used": response.usage.total_tokens if hasattr(response, 'usage') else max_tokens,
                "error": None
            }
            
        except Exception as e:
            processing_time = (datetime.now() - start_time).total_seconds()
            error_msg = str(e)
            logger.error(f"OpenAI API ì˜¤ë¥˜: {error_msg}")
            
            return {
                "ai_strengths": f"AI ë¶„ì„ ì˜¤ë¥˜: {error_msg}",
                "ai_weaknesses": "AI ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "ai_feedback": f"OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}",
                "processing_time": round(processing_time, 2),
                "model_used": model,
                "tokens_used": 0,
                "error": error_msg
            }
    
    def create_airiss_prompt(self, uid: str, opinion: str, model: str, max_tokens: int) -> str:
        """AIRISS ë§ì¶¤ AI í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""
AIRISS ì§ì› {uid}ì˜ í‰ê°€ ì˜ê²¬ì„ 8ëŒ€ ì˜ì—­ì„ ê¸°ë°˜ìœ¼ë¡œ ì¢…í•© ë¶„ì„í•´ì£¼ì„¸ìš”.

ã€í‰ê°€ ì˜ê²¬ã€‘
{opinion[:1500]}

ã€AIRISS 8ëŒ€ ì˜ì—­ã€‘
1. ì—…ë¬´ì„±ê³¼ (25%) - ì—…ë¬´ ì‚°ì¶œë¬¼ì˜ ì–‘ê³¼ ì§ˆ
2. KPIë‹¬ì„± (20%) - í•µì‹¬ì„±ê³¼ì§€í‘œ ë‹¬ì„±ë„  
3. íƒœë„ë§ˆì¸ë“œ (15%) - ì—…ë¬´ì— ëŒ€í•œ íƒœë„ì™€ ë§ˆì¸ë“œì…‹
4. ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ (15%) - ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ê³¼ ìŠ¤íƒ€ì¼
5. ë¦¬ë”ì‹­í˜‘ì—… (10%) - ë¦¬ë”ì‹­ê³¼ í˜‘ì—… ëŠ¥ë ¥
6. ì „ë¬¸ì„±í•™ìŠµ (8%) - ì „ë¬¸ì„±ê³¼ í•™ìŠµëŠ¥ë ¥
7. ì°½ì˜í˜ì‹  (5%) - ì°½ì˜ì„±ê³¼ í˜ì‹  ë§ˆì¸ë“œ
8. ì¡°ì§ì ì‘ (2%) - ì¡°ì§ë¬¸í™” ì ì‘ë„ì™€ ìœ¤ë¦¬ì„±

ã€ì¶œë ¥ í˜•ì‹ã€‘
[ì¥ì ]
1. í•µì‹¬ì¥ì 1 (ê´€ë ¨ AIRISS ì˜ì—­ ëª…ì‹œ)
2. í•µì‹¬ì¥ì 2 (ê´€ë ¨ AIRISS ì˜ì—­ ëª…ì‹œ)
3. í•µì‹¬ì¥ì 3 (ê´€ë ¨ AIRISS ì˜ì—­ ëª…ì‹œ)

[ê°œì„ ì ]
1. ê°œì„ ì 1 (ê´€ë ¨ AIRISS ì˜ì—­ ëª…ì‹œ)
2. ê°œì„ ì 2 (ê´€ë ¨ AIRISS ì˜ì—­ ëª…ì‹œ)
3. ê°œì„ ì 3 (ê´€ë ¨ AIRISS ì˜ì—­ ëª…ì‹œ)

[ì¢…í•© í”¼ë“œë°±]
AIRISS 8ëŒ€ ì˜ì—­ì„ ì¢…í•©í•˜ì—¬ ì‹¤í–‰ ê°€ëŠ¥í•œ í”¼ë“œë°±ì„ 500-700ìë¡œ ì‘ì„±
        """
    
    def parse_ai_response(self, response: str) -> tuple:
        """AI ì‘ë‹µ íŒŒì‹±"""
        try:
            sections = response.split('[')
            
            strengths = ""
            weaknesses = ""
            feedback = ""
            
            for section in sections:
                section = section.strip()
                if section.startswith('ì¥ì ]'):
                    content = section.replace('ì¥ì ]', '').strip()
                    if '[' in content:
                        content = content.split('[')[0].strip()
                    strengths = content
                        
                elif section.startswith('ê°œì„ ì ]'):
                    content = section.replace('ê°œì„ ì ]', '').strip()
                    if '[' in content:
                        content = content.split('[')[0].strip()
                    weaknesses = content
                        
                elif section.startswith('ì¢…í•© í”¼ë“œë°±]') or section.startswith('ì¢…í•©í”¼ë“œë°±]'):
                    content = section.replace('ì¢…í•© í”¼ë“œë°±]', '').replace('ì¢…í•©í”¼ë“œë°±]', '').strip()
                    feedback = content
            
            if not strengths.strip():
                strengths = "AIRISS ë¶„ì„ì„ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ ê¸ì •ì  íŠ¹ì„±ì´ ê´€ì°°ë©ë‹ˆë‹¤."
            if not weaknesses.strip():
                weaknesses = "ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•˜ë‚˜, ì§€ì†ì ì¸ ì„±ì¥ì„ ìœ„í•œ ê°œì„  ê¸°íšŒê°€ ìˆìŠµë‹ˆë‹¤."
            if not feedback.strip():
                feedback = response
            
            strengths = self.clean_text(strengths)
            weaknesses = self.clean_text(weaknesses)
            feedback = self.clean_text(feedback)
                
            return strengths, weaknesses, feedback
            
        except Exception as e:
            logger.error(f"AI ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return "ì¥ì  ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", "ê°œì„ ì  ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", response
    
    def clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if not text:
            return ""
        
        text = '\n'.join(line.strip() for line in text.split('\n') if line.strip())
        
        if len(text) > 1000:
            text = text[:1000] + "..."
        
        return text.strip()

class AIRISSHybridAnalyzer:
    """í…ìŠ¤íŠ¸ ë¶„ì„ + ì •ëŸ‰ ë¶„ì„ í†µí•© í´ë˜ìŠ¤ (v3.0 ê°•í™”)"""
    
    def __init__(self):
        self.text_analyzer = AIRISSAnalyzer()
        self.quantitative_analyzer = QuantitativeAnalyzer()
        
        self.hybrid_weights = {
            'text_analysis': 0.6,
            'quantitative_analysis': 0.4
        }
        
        logger.info("âœ… AIRISS v4.0 í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def comprehensive_analysis(self, uid: str, opinion: str, row_data: pd.Series) -> Dict[str, Any]:
        """ì¢…í•© ë¶„ì„: í…ìŠ¤íŠ¸ + ì •ëŸ‰ ë°ì´í„°"""
        
        # 1. í…ìŠ¤íŠ¸ ë¶„ì„
        text_results = {}
        for dimension in AIRISS_FRAMEWORK.keys():
            text_results[dimension] = self.text_analyzer.analyze_text(opinion, dimension)
        
        text_overall = self.text_analyzer.calculate_overall_score(
            {dim: result["score"] for dim, result in text_results.items()}
        )
        
        # 2. ì •ëŸ‰ ë°ì´í„° ë¶„ì„
        quant_data = self.quantitative_analyzer.extract_quantitative_data(row_data)
        quant_results = self.quantitative_analyzer.calculate_quantitative_score(quant_data)
        
        # 3. í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°
        text_weight = self.hybrid_weights['text_analysis']
        quant_weight = self.hybrid_weights['quantitative_analysis']
        
        # ì •ëŸ‰ ë°ì´í„° í’ˆì§ˆì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì¡°ì •
        if quant_results["data_quality"] == "ì—†ìŒ":
            text_weight = 0.8
            quant_weight = 0.2
        elif quant_results["data_quality"] == "ë‚®ìŒ":
            text_weight = 0.7
            quant_weight = 0.3
        
        hybrid_score = (text_overall["overall_score"] * text_weight + 
                       quant_results["quantitative_score"] * quant_weight)
        
        # 4. í†µí•© ì‹ ë¢°ë„ ê³„ì‚°
        hybrid_confidence = (text_overall.get("confidence", 70) * text_weight + 
                           quant_results["confidence"] * quant_weight)
        
        # 5. í•˜ì´ë¸Œë¦¬ë“œ ë“±ê¸‰ ì‚°ì •
        hybrid_grade_info = self.calculate_hybrid_grade(hybrid_score)
        
        return {
            "text_analysis": {
                "overall_score": text_overall["overall_score"],
                "grade": text_overall["grade"],
                "dimension_scores": {dim: result["score"] for dim, result in text_results.items()},
                "dimension_details": text_results
            },
            "quantitative_analysis": quant_results,
            "hybrid_analysis": {
                "overall_score": round(hybrid_score, 1),
                "grade": hybrid_grade_info["grade"],
                "grade_description": hybrid_grade_info["grade_description"],
                "percentile": hybrid_grade_info["percentile"],
                "confidence": round(hybrid_confidence, 1),
                "analysis_composition": {
                    "text_weight": round(text_weight * 100, 1),
                    "quantitative_weight": round(quant_weight * 100, 1)
                }
            },
            "analysis_metadata": {
                "uid": uid,
                "analysis_version": "AIRISS v4.0",
                "analysis_timestamp": datetime.now().isoformat(),
                "data_sources": {
                    "text_available": bool(opinion and opinion.strip()),
                    "quantitative_available": bool(quant_data),
                    "quantitative_data_quality": quant_results["data_quality"]
                }
            }
        }
    
    def calculate_hybrid_grade(self, score: float) -> Dict[str, str]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ë¥¼ OKë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
        if score >= 95:
            return {
                "grade": "OKâ˜…â˜…â˜…",
                "grade_description": "ìµœìš°ìˆ˜ ë“±ê¸‰ (TOP 1%) - AIRISS v4.0 í•˜ì´ë¸Œë¦¬ë“œ",
                "percentile": "ìƒìœ„ 1%"
            }
        elif score >= 90:
            return {
                "grade": "OKâ˜…â˜…",
                "grade_description": "ìš°ìˆ˜ ë“±ê¸‰ (TOP 5%) - AIRISS v4.0 í•˜ì´ë¸Œë¦¬ë“œ",
                "percentile": "ìƒìœ„ 5%"
            }
        elif score >= 85:
            return {
                "grade": "OKâ˜…",
                "grade_description": "ìš°ìˆ˜+ ë“±ê¸‰ (TOP 10%) - AIRISS v4.0 í•˜ì´ë¸Œë¦¬ë“œ",
                "percentile": "ìƒìœ„ 10%"
            }
        elif score >= 80:
            return {
                "grade": "OK A",
                "grade_description": "ì–‘í˜¸ ë“±ê¸‰ (TOP 20%) - AIRISS v4.0 í•˜ì´ë¸Œë¦¬ë“œ",
                "percentile": "ìƒìœ„ 20%"
            }
        elif score >= 75:
            return {
                "grade": "OK B+",
                "grade_description": "ì–‘í˜¸- ë“±ê¸‰ (TOP 30%) - AIRISS v4.0 í•˜ì´ë¸Œë¦¬ë“œ",
                "percentile": "ìƒìœ„ 30%"
            }
        elif score >= 70:
            return {
                "grade": "OK B",
                "grade_description": "ë³´í†µ ë“±ê¸‰ (TOP 40%) - AIRISS v4.0 í•˜ì´ë¸Œë¦¬ë“œ",
                "percentile": "ìƒìœ„ 40%"
            }
        elif score >= 60:
            return {
                "grade": "OK C",
                "grade_description": "ê°œì„ í•„ìš” ë“±ê¸‰ (TOP 60%) - AIRISS v4.0 í•˜ì´ë¸Œë¦¬ë“œ",
                "percentile": "ìƒìœ„ 60%"
            }
        else:
            return {
                "grade": "OK D",
                "grade_description": "ì§‘ì¤‘ê°œì„  ë“±ê¸‰ (í•˜ìœ„ 40%) - AIRISS v4.0 í•˜ì´ë¸Œë¦¬ë“œ",
                "percentile": "í•˜ìœ„ 40%"
            }

# ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
hybrid_analyzer = AIRISSHybridAnalyzer()

# main.pyì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ AnalysisEngine alias
AnalysisEngine = AIRISSHybridAnalyzer