import logging
from typing import Dict, Any, List, Optional
import pandas as pd
import numpy as np
from datetime import datetime
import asyncio
import re

from sqlalchemy.orm import Session
from app.models.job import Job

logger = logging.getLogger(__name__)

# AIRISS 8ëŒ€ ì˜ì—­ í”„ë ˆì„ì›Œí¬ (v3.0ì—ì„œ ê°€ì ¸ì˜´)
AIRISS_FRAMEWORK = {
    "ì—…ë¬´ì„±ê³¼": {
        "keywords": {
            "positive": [
                "ìš°ìˆ˜", "íƒì›”", "ë›°ì–´ë‚¨", "ì„±ê³¼", "ë‹¬ì„±", "ì™„ë£Œ", "ì„±ê³µ", "íš¨ìœ¨", "ìƒì‚°ì ", 
                "ëª©í‘œë‹¬ì„±", "ì´ˆê³¼ë‹¬ì„±", "í’ˆì§ˆ", "ì •í™•", "ì‹ ì†", "ì™„ë²½", "ì „ë¬¸ì ", "ì²´ê³„ì ",
                "ì„±ê³¼ê°€", "ê²°ê³¼ë¥¼", "ì‹¤ì ì´", "ì™„ì„±ë„", "ë§Œì¡±ë„"
            ],
            "negative": [
                "ë¶€ì¡±", "ë¯¸í¡", "ì§€ì—°", "ì‹¤íŒ¨", "ë¬¸ì œ", "ì˜¤ë¥˜", "ëŠ¦ìŒ", "ë¹„íš¨ìœ¨", 
                "ëª©í‘œë¯¸ë‹¬", "í’ˆì§ˆì €í•˜", "ë¶€ì •í™•", "ë¯¸ì™„ì„±", "ë¶€ì‹¤", "ê°œì„ ", "ë³´ì™„"
            ]
        },
        "weight": 0.25,
        "description": "ì—…ë¬´ ì‚°ì¶œë¬¼ì˜ ì–‘ê³¼ ì§ˆ",
        "color": "#FF5722",
        "icon": "ğŸ“Š"
    },
    "KPIë‹¬ì„±": {
        "keywords": {
            "positive": [
                "KPIë‹¬ì„±", "ì§€í‘œë‹¬ì„±", "ëª©í‘œì´ˆê³¼", "ì„±ê³¼ìš°ìˆ˜", "ì‹¤ì ìš°ìˆ˜", "ë§¤ì¶œì¦ê°€", 
                "íš¨ìœ¨í–¥ìƒ", "ìƒì‚°ì„±í–¥ìƒ", "ìˆ˜ì¹˜ë‹¬ì„±", "ì„±ì¥", "ê°œì„ ", "ë‹¬ì„±ë¥ ", "ì´ˆê³¼"
            ],
            "negative": [
                "KPIë¯¸ë‹¬", "ëª©í‘œë¯¸ë‹¬", "ì‹¤ì ë¶€ì§„", "ë§¤ì¶œê°ì†Œ", "íš¨ìœ¨ì €í•˜", 
                "ìƒì‚°ì„±ì €í•˜", "ìˆ˜ì¹˜ë¶€ì¡±", "í•˜ë½", "í‡´ë³´", "ë¯¸ë‹¬"
            ]
        },
        "weight": 0.20,
        "description": "í•µì‹¬ì„±ê³¼ì§€í‘œ ë‹¬ì„±ë„",
        "color": "#4A4A4A",
        "icon": "ğŸ¯"
    },
    "íƒœë„ë§ˆì¸ë“œ": {
        "keywords": {
            "positive": [
                "ì ê·¹ì ", "ê¸ì •ì ", "ì—´ì •", "ì„±ì‹¤", "ì±…ì„ê°", "ì§„ì·¨ì ", "í˜‘ì¡°ì ", 
                "ì„±ì¥ì§€í–¥", "í•™ìŠµì˜ì§€", "ë„ì „ì •ì‹ ", "ì£¼ì¸ì˜ì‹", "í—Œì‹ ", "ì—´ì‹¬íˆ", "ë…¸ë ¥"
            ],
            "negative": [
                "ì†Œê·¹ì ", "ë¶€ì •ì ", "ë¬´ê´€ì‹¬", "ë¶ˆì„±ì‹¤", "íšŒí”¼", "ëƒ‰ì†Œì ", 
                "ë¹„í˜‘ì¡°ì ", "ì•ˆì£¼", "í˜„ìƒìœ ì§€", "ìˆ˜ë™ì ", "íƒœë„", "ë§ˆì¸ë“œ"
            ]
        },
        "weight": 0.15,
        "description": "ì—…ë¬´ì— ëŒ€í•œ íƒœë„ì™€ ë§ˆì¸ë“œì…‹",
        "color": "#F89C26",
        "icon": "ğŸ§ "
    },
    "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜": {
        "keywords": {
            "positive": [
                "ëª…í™•", "ì •í™•", "ì‹ ì†", "ì¹œì ˆ", "ê²½ì²­", "ì†Œí†µ", "ì „ë‹¬", "ì´í•´", 
                "ì„¤ë“", "í˜‘ì˜", "ì¡°ìœ¨", "ê³µìœ ", "íˆ¬ëª…", "ê°œë°©ì ", "ì˜ì‚¬ì†Œí†µ", "ì›í™œ"
            ],
            "negative": [
                "ë¶ˆëª…í™•", "ì§€ì—°", "ë¬´ì‹œ", "ì˜¤í•´", "ë‹¨ì ˆ", "ì¹¨ë¬µ", "íšŒí”¼", 
                "ë…ë‹¨", "ì¼ë°©ì ", "íì‡„ì ", "ì†Œí†µë¶€ì¡±", "ì „ë‹¬ë ¥"
            ]
        },
        "weight": 0.15,
        "description": "ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ê³¼ ìŠ¤íƒ€ì¼",
        "color": "#B3B3B3",
        "icon": "ğŸ’¬"
    },
    "ë¦¬ë”ì‹­í˜‘ì—…": {
        "keywords": {
            "positive": [
                "ë¦¬ë”ì‹­", "íŒ€ì›Œí¬", "í˜‘ì—…", "ì§€ì›", "ë©˜í† ë§", "ë™ê¸°ë¶€ì—¬", "ì¡°ìœ¨", 
                "í™”í•©", "íŒ€ë¹Œë”©", "ìœ„ì„", "ì½”ì¹­", "ì˜í–¥ë ¥", "í˜‘ë ¥", "íŒ€í”Œë ˆì´"
            ],
            "negative": [
                "ë…ë‹¨", "ê°ˆë“±", "ë¹„í˜‘ì¡°", "ì†Œì™¸", "ë¶„ì—´", "ëŒ€ë¦½", "ì´ê¸°ì£¼ì˜", 
                "ë°©í•´", "ë¬´ê´€ì‹¬", "ê³ ë¦½", "ê°œì¸ì£¼ì˜"
            ]
        },
        "weight": 0.10,
        "description": "ë¦¬ë”ì‹­ê³¼ í˜‘ì—… ëŠ¥ë ¥",
        "color": "#FF8A50",
        "icon": "ğŸ‘¥"
    },
    "ì „ë¬¸ì„±í•™ìŠµ": {
        "keywords": {
            "positive": [
                "ì „ë¬¸", "ìˆ™ë ¨", "ê¸°ìˆ ", "ì§€ì‹", "í•™ìŠµ", "ë°œì „", "ì—­ëŸ‰", "ëŠ¥ë ¥", 
                "ì„±ì¥", "í–¥ìƒ", "ìŠµë“", "ê°œë°œ", "ì „ë¬¸ì„±", "ë…¸í•˜ìš°", "ìŠ¤í‚¬", "ê²½í—˜"
            ],
            "negative": [
                "ë¯¸ìˆ™", "ë¶€ì¡±", "ë‚™í›„", "ë¬´ì§€", "ì •ì²´", "í‡´ë³´", "ë¬´ëŠ¥ë ¥", 
                "ê¸°ì´ˆë¶€ì¡±", "ì—­ëŸ‰ë¶€ì¡±", "ì‹¤ë ¥ë¶€ì¡±"
            ]
        },
        "weight": 0.08,
        "description": "ì „ë¬¸ì„±ê³¼ í•™ìŠµëŠ¥ë ¥",
        "color": "#6A6A6A",
        "icon": "ğŸ“š"
    },
    "ì°½ì˜í˜ì‹ ": {
        "keywords": {
            "positive": [
                "ì°½ì˜", "í˜ì‹ ", "ì•„ì´ë””ì–´", "ê°œì„ ", "íš¨ìœ¨í™”", "ìµœì í™”", "ìƒˆë¡œìš´", 
                "ë„ì „", "ë³€í™”", "ë°œìƒ", "ì°½ì¡°", "í˜ì‹ ì ", "ë…ì°½ì ", "ì°½ì¡°ì "
            ],
            "negative": [
                "ë³´ìˆ˜ì ", "ê²½ì§", "í‹€ì—ë°•íŒ", "ë³€í™”ê±°ë¶€", "ê¸°ì¡´ë°©ì‹", "ê´€ìŠµì ", 
                "ê²½ì§ëœ", "ê³ ì •ì ", "ë³€í™”ì—†ì´"
            ]
        },
        "weight": 0.05,
        "description": "ì°½ì˜ì„±ê³¼ í˜ì‹  ë§ˆì¸ë“œ",
        "color": "#FFA726",
        "icon": "ğŸ’¡"
    },
    "ì¡°ì§ì ì‘": {
        "keywords": {
            "positive": [
                "ì ì‘", "ìœµí™”", "ì¡°í™”", "ë¬¸í™”", "ê·œì¹™ì¤€ìˆ˜", "ìœ¤ë¦¬", "ì‹ ë¢°", 
                "ì•ˆì •", "ì¼ê´€ì„±", "ì„±ì‹¤ì„±", "ì¡°ì§", "íšŒì‚¬", "íŒ€ì—"
            ],
            "negative": [
                "ë¶€ì ì‘", "ê°ˆë“±", "ìœ„ë°˜", "ë¹„ìœ¤ë¦¬", "ë¶ˆì‹ ", "ì¼íƒˆ", 
                "ë¬¸ì œí–‰ë™", "ê·œì •ìœ„ë°˜", "ì¡°ì§ê³¼"
            ]
        },
        "weight": 0.02,
        "description": "ì¡°ì§ë¬¸í™” ì ì‘ë„ì™€ ìœ¤ë¦¬ì„±",
        "color": "#9E9E9E",
        "icon": "ğŸ¢"
    }
}


class TextAnalyzer:
    """í…ìŠ¤íŠ¸ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.framework = AIRISS_FRAMEWORK
        logger.info("í…ìŠ¤íŠ¸ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def analyze_text(self, text: str, dimension: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì ìˆ˜ ì‚°ì¶œ"""
        if not text or text.lower() in ['nan', 'null', '', 'none']:
            return {
                "score": 50,
                "confidence": 0,
                "signals": {"positive": 0, "negative": 0, "positive_words": [], "negative_words": []}
            }
        
        keywords = self.framework[dimension]["keywords"]
        text_lower = text.lower()
        
        # í‚¤ì›Œë“œ ë§¤ì¹­
        positive_matches = []
        negative_matches = []
        
        for word in keywords["positive"]:
            if word in text_lower:
                positive_matches.append(word)
        
        for word in keywords["negative"]:
            if word in text_lower:
                negative_matches.append(word)
        
        positive_count = len(positive_matches)
        negative_count = len(negative_matches)
        
        # ì ìˆ˜ ê³„ì‚°
        base_score = 50
        positive_boost = min(positive_count * 8, 45)
        negative_penalty = min(negative_count * 10, 40)
        
        text_length = len(text)
        if text_length > 50:
            length_bonus = min((text_length - 50) / 100 * 5, 10)
        else:
            length_bonus = 0
        
        final_score = base_score + positive_boost - negative_penalty + length_bonus
        final_score = max(10, min(100, final_score))
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        total_signals = positive_count + negative_count
        base_confidence = min(total_signals * 12, 80)
        length_confidence = min(text_length / 20, 20)
        confidence = min(base_confidence + length_confidence, 100)
        
        return {
            "score": round(final_score, 1),
            "confidence": round(confidence, 1),
            "signals": {
                "positive": positive_count,
                "negative": negative_count,
                "positive_words": positive_matches[:5],
                "negative_words": negative_matches[:5]
            }
        }
    
    def calculate_overall_score(self, dimension_scores: Dict[str, float]) -> Dict[str, Any]:
        """ì¢…í•© ì ìˆ˜ ê³„ì‚°"""
        weighted_sum = 0
        total_weight = 0
        
        for dimension, score in dimension_scores.items():
            if dimension in self.framework:
                weight = self.framework[dimension]["weight"]
                weighted_sum += score * weight
                total_weight += weight
        
        overall_score = weighted_sum / total_weight if total_weight > 0 else 50
        
        # ë“±ê¸‰ ê²°ì •
        if overall_score >= 95:
            grade = "OKâ˜…â˜…â˜…"
            grade_desc = "ìµœìš°ìˆ˜ ë“±ê¸‰ (TOP 1%)"
            percentile = "ìƒìœ„ 1%"
        elif overall_score >= 90:
            grade = "OKâ˜…â˜…"
            grade_desc = "ìš°ìˆ˜ ë“±ê¸‰ (TOP 5%)"
            percentile = "ìƒìœ„ 5%"
        elif overall_score >= 85:
            grade = "OKâ˜…"
            grade_desc = "ìš°ìˆ˜+ ë“±ê¸‰ (TOP 10%)"
            percentile = "ìƒìœ„ 10%"
        elif overall_score >= 80:
            grade = "OK A"
            grade_desc = "ì–‘í˜¸ ë“±ê¸‰ (TOP 20%)"
            percentile = "ìƒìœ„ 20%"
        elif overall_score >= 75:
            grade = "OK B+"
            grade_desc = "ì–‘í˜¸- ë“±ê¸‰ (TOP 30%)"
            percentile = "ìƒìœ„ 30%"
        elif overall_score >= 70:
            grade = "OK B"
            grade_desc = "ë³´í†µ ë“±ê¸‰ (TOP 40%)"
            percentile = "ìƒìœ„ 40%"
        elif overall_score >= 60:
            grade = "OK C"
            grade_desc = "ê°œì„ í•„ìš” ë“±ê¸‰ (TOP 60%)"
            percentile = "ìƒìœ„ 60%"
        else:
            grade = "OK D"
            grade_desc = "ì§‘ì¤‘ê°œì„  ë“±ê¸‰ (í•˜ìœ„ 40%)"
            percentile = "í•˜ìœ„ 40%"
        
        return {
            "overall_score": round(overall_score, 1),
            "grade": grade,
            "grade_description": grade_desc,
            "percentile": percentile,
            "weighted_scores": dimension_scores
        }


class QuantitativeAnalyzer:
    """ì •ëŸ‰ë°ì´í„° ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.grade_mappings = self.setup_grade_mappings()
        self.score_weights = self.setup_score_weights()
        logger.info("ì •ëŸ‰ë°ì´í„° ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def setup_grade_mappings(self) -> Dict[str, Dict]:
        """ë“±ê¸‰ ë³€í™˜ ë§¤í•‘"""
        return {
            # 5ë‹¨ê³„ ë“±ê¸‰
            'S': 100, 'A': 85, 'B': 70, 'C': 55, 'D': 40,
            
            # ì˜ë¬¸ ë“±ê¸‰  
            'A+': 100, 'A': 95, 'A-': 90,
            'B+': 85, 'B': 80, 'B-': 75,
            'C+': 70, 'C': 65, 'C-': 60,
            'D+': 55, 'D': 50, 'D-': 45,
            'F': 30,
            
            # ìˆ«ì ë“±ê¸‰
            '1': 100, '2': 80, '3': 60, '4': 40, '5': 20,
            '1ê¸‰': 100, '2ê¸‰': 80, '3ê¸‰': 60, '4ê¸‰': 40, '5ê¸‰': 20,
            
            # í•œê¸€ ë“±ê¸‰
            'ìš°ìˆ˜': 90, 'ì–‘í˜¸': 75, 'ë³´í†µ': 60, 'ë¯¸í¡': 45, 'ë¶€ì¡±': 30,
            'ìµœìš°ìˆ˜': 100, 'ìƒ': 85, 'ì¤‘': 65, 'í•˜': 45,
            
            # ë°±ë¶„ìœ„/í¼ì„¼íŠ¸
            'ìƒìœ„10%': 95, 'ìƒìœ„20%': 85, 'ìƒìœ„30%': 75, 
            'ìƒìœ„50%': 65, 'í•˜ìœ„50%': 50, 'í•˜ìœ„30%': 35,
            
            # OKê¸ˆìœµê·¸ë£¹ ë§ì¶¤ ë“±ê¸‰
            'OKâ˜…â˜…â˜…': 100, 'OKâ˜…â˜…': 90, 'OKâ˜…': 80, 
            'OK A': 75, 'OK B+': 70, 'OK B': 65, 'OK C': 55, 'OK D': 40
        }
    
    def setup_score_weights(self) -> Dict[str, float]:
        """í•­ëª©ë³„ ê°€ì¤‘ì¹˜"""
        return {
            'performance_grade': 0.30,
            'kpi_score': 0.25,
            'competency_grade': 0.20,
            'attendance_score': 0.10,
            'training_score': 0.10,
            'certificate_score': 0.05
        }
    
    def extract_quantitative_data(self, row: pd.Series) -> Dict[str, Any]:
        """ì •ëŸ‰ ë°ì´í„° ì¶”ì¶œ"""
        quant_data = {}
        
        for col_name, value in row.items():
            col_lower = str(col_name).lower()
            
            # ì ìˆ˜ ê´€ë ¨
            if any(keyword in col_lower for keyword in ['ì ìˆ˜', 'score', 'í‰ì ', 'rating']):
                quant_data[f'score_{col_name}'] = self.normalize_score(value)
            
            # ë“±ê¸‰ ê´€ë ¨
            elif any(keyword in col_lower for keyword in ['ë“±ê¸‰', 'grade', 'í‰ê°€', 'level']):
                quant_data[f'grade_{col_name}'] = self.convert_grade_to_score(value)
            
            # ë‹¬ì„±ë¥ /ë°±ë¶„ìœ¨
            elif any(keyword in col_lower for keyword in ['ë‹¬ì„±ë¥ ', 'ë¹„ìœ¨', 'rate', '%', 'percent']):
                quant_data[f'rate_{col_name}'] = self.normalize_percentage(value)
            
            # íšŸìˆ˜/ê±´ìˆ˜
            elif any(keyword in col_lower for keyword in ['íšŸìˆ˜', 'ê±´ìˆ˜', 'count', 'íšŒ', 'ë²ˆ']):
                quant_data[f'count_{col_name}'] = self.normalize_count(value)
                
        return quant_data
    
    def convert_grade_to_score(self, grade_value) -> float:
        """ë“±ê¸‰ì„ ì ìˆ˜ë¡œ ë³€í™˜"""
        if pd.isna(grade_value) or grade_value == '':
            return 50.0
        
        grade_str = str(grade_value).strip().upper()
        
        # ì§ì ‘ ë§¤í•‘
        if grade_str in self.grade_mappings:
            return float(self.grade_mappings[grade_str])
        
        # ìˆ«ì ì ìˆ˜
        try:
            score = float(grade_str)
            if 0 <= score <= 100:
                return score
            elif 0 <= score <= 5:
                return (score - 1) * 25
            elif 0 <= score <= 10:
                return score * 10
        except ValueError:
            pass
        
        # íŒ¨í„´ ë§¤ì¹­
        if 'ìš°ìˆ˜' in grade_str or 'excellent' in grade_str.lower():
            return 90.0
        elif 'ì–‘í˜¸' in grade_str or 'good' in grade_str.lower():
            return 75.0
        elif 'ë³´í†µ' in grade_str or 'average' in grade_str.lower():
            return 60.0
        elif 'ë¯¸í¡' in grade_str or 'poor' in grade_str.lower():
            return 45.0
        
        logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ë“±ê¸‰ í˜•ì‹: {grade_value}, ê¸°ë³¸ê°’ 50 ì ìš©")
        return 50.0
    
    def normalize_score(self, score_value) -> float:
        """ì ìˆ˜ ì •ê·œí™”"""
        if pd.isna(score_value) or score_value == '':
            return 50.0
        
        try:
            score = float(str(score_value).replace('%', '').replace('ì ', ''))
            
            if 0 <= score <= 1:
                return score * 100
            elif 0 <= score <= 5:
                return (score - 1) * 25
            elif 0 <= score <= 10:
                return score * 10
            elif 0 <= score <= 100:
                return score
            else:
                return max(0, min(100, score))
                
        except (ValueError, TypeError):
            logger.warning(f"ì ìˆ˜ ë³€í™˜ ì‹¤íŒ¨: {score_value}, ê¸°ë³¸ê°’ 50 ì ìš©")
            return 50.0
    
    def normalize_percentage(self, percent_value) -> float:
        """ë°±ë¶„ìœ¨ ì •ê·œí™”"""
        if pd.isna(percent_value) or percent_value == '':
            return 50.0
        
        try:
            percent_str = str(percent_value).replace('%', '').replace('í¼ì„¼íŠ¸', '')
            percent = float(percent_str)
            
            if 0 <= percent <= 1:
                return percent * 100
            elif 0 <= percent <= 100:
                return percent
            else:
                return max(0, min(100, percent))
                
        except (ValueError, TypeError):
            logger.warning(f"ë°±ë¶„ìœ¨ ë³€í™˜ ì‹¤íŒ¨: {percent_value}, ê¸°ë³¸ê°’ 50 ì ìš©")
            return 50.0
    
    def normalize_count(self, count_value) -> float:
        """íšŸìˆ˜ë¥¼ ì ìˆ˜ë¡œ ë³€í™˜"""
        if pd.isna(count_value) or count_value == '':
            return 50.0
        
        try:
            count = float(str(count_value).replace('íšŒ', '').replace('ê±´', '').replace('ë²ˆ', ''))
            
            if count <= 0:
                return 30.0
            elif count <= 2:
                return 50.0
            elif count <= 5:
                return 70.0
            elif count <= 10:
                return 85.0
            else:
                return 95.0
                
        except (ValueError, TypeError):
            logger.warning(f"íšŸìˆ˜ ë³€í™˜ ì‹¤íŒ¨: {count_value}, ê¸°ë³¸ê°’ 50 ì ìš©")
            return 50.0
    
    def calculate_quantitative_score(self, quant_data: Dict[str, float]) -> Dict[str, Any]:
        """ì •ëŸ‰ ì ìˆ˜ ê³„ì‚°"""
        if not quant_data:
            return {
                "quantitative_score": 50.0,
                "confidence": 0.0,
                "contributing_factors": {},
                "data_quality": "ì—†ìŒ"
            }
        
        # ê°€ì¤‘í‰ê·  ê³„ì‚°
        total_score = 0.0
        total_weight = 0.0
        contributing_factors = {}
        
        for data_key, score in quant_data.items():
            # ìœ í˜•ë³„ ê°€ì¤‘ì¹˜
            if 'grade_' in data_key:
                weight = 0.4
            elif 'score_' in data_key:
                weight = 0.3
            elif 'rate_' in data_key:
                weight = 0.2
            else:
                weight = 0.1
            
            total_score += score * weight
            total_weight += weight
            contributing_factors[data_key] = {
                "score": round(score, 1),
                "weight": weight,
                "contribution": round(score * weight, 1)
            }
        
        # ìµœì¢… ì ìˆ˜
        if total_weight > 0:
            final_score = total_score / total_weight
            confidence = min(total_weight * 20, 100)
        else:
            final_score = 50.0
            confidence = 0.0
        
        # ë°ì´í„° í’ˆì§ˆ
        data_count = len(quant_data)
        if data_count >= 5:
            data_quality = "ë†’ìŒ"
        elif data_count >= 3:
            data_quality = "ì¤‘ê°„"
        elif data_count >= 1:
            data_quality = "ë‚®ìŒ"
        else:
            data_quality = "ì—†ìŒ"
        
        return {
            "quantitative_score": round(final_score, 1),
            "confidence": round(confidence, 1),
            "contributing_factors": contributing_factors,
            "data_quality": data_quality,
            "data_count": data_count
        }


class AIRISSEngine:
    """AIRISS v4.0 í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì—”ì§„"""
    
    def __init__(self):
        self.text_analyzer = TextAnalyzer()
        self.quantitative_analyzer = QuantitativeAnalyzer()
        self.hybrid_weights = {
            'text_analysis': 0.6,
            'quantitative_analysis': 0.4
        }
        logger.info("AIRISS v4.0 ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def analyze_dataframe(
        self,
        df: pd.DataFrame,
        analysis_mode: str,
        enable_ai: bool,
        api_key: Optional[str],
        model: str,
        max_tokens: int,
        job_id: str,
        db: Session
    ) -> List[Dict[str, Any]]:
        """DataFrame ì „ì²´ ë¶„ì„"""
        results = []
        
        # ì»¬ëŸ¼ ê°ì§€
        uid_columns = self._detect_uid_columns(df)
        opinion_columns = self._detect_opinion_columns(df)
        
        for idx, row in df.iterrows():
            try:
                # UIDì™€ ì˜ê²¬ ì¶”ì¶œ
                uid = str(row[uid_columns[0]]) if uid_columns else f"user_{idx}"
                opinion = str(row[opinion_columns[0]]) if opinion_columns else ""
                
                # ë¹ˆ ì˜ê²¬ ì²˜ë¦¬
                if not opinion or opinion.lower() in ['nan', 'null', '', 'none']:
                    if analysis_mode != "quantitative":
                        continue
                    opinion = ""
                
                # ë¶„ì„ ì‹¤í–‰
                result = await self.analyze_single_record(
                    uid, opinion, row, analysis_mode, enable_ai, api_key, model, max_tokens
                )
                results.append(result)
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                progress = (len(results) / len(df)) * 100
                job = db.query(Job).filter(Job.id == job_id).first()
                if job:
                    job.processed = len(results)
                    job.progress = progress
                    db.commit()
                
                # ì†ë„ ì¡°ì ˆ
                if enable_ai and api_key:
                    await asyncio.sleep(1)
                else:
                    await asyncio.sleep(0.01)
                    
            except Exception as e:
                logger.error(f"ê°œë³„ ë¶„ì„ ì˜¤ë¥˜ - UID {uid}: {e}")
                continue
        
        return results
    
    async def analyze_single_record(
        self,
        uid: str,
        opinion: str,
        row: pd.Series,
        analysis_mode: str,
        enable_ai: bool,
        api_key: Optional[str],
        model: str,
        max_tokens: int
    ) -> Dict[str, Any]:
        """ê°œë³„ ë ˆì½”ë“œ ë¶„ì„"""
        
        # í…ìŠ¤íŠ¸ ë¶„ì„
        text_results = {}
        dimension_scores = {}
        for dimension in AIRISS_FRAMEWORK.keys():
            result = self.text_analyzer.analyze_text(opinion, dimension)
            text_results[dimension] = result
            dimension_scores[dimension] = result["score"]
        
        text_overall = self.text_analyzer.calculate_overall_score(dimension_scores)
        
        # ì •ëŸ‰ ë¶„ì„
        quant_data = self.quantitative_analyzer.extract_quantitative_data(row)
        quant_results = self.quantitative_analyzer.calculate_quantitative_score(quant_data)
        
        # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°
        if analysis_mode == "text":
            hybrid_score = text_overall["overall_score"]
            hybrid_confidence = text_overall.get("confidence", 70)
        elif analysis_mode == "quantitative":
            hybrid_score = quant_results["quantitative_score"]
            hybrid_confidence = quant_results["confidence"]
        else:  # hybrid
            text_weight = self.hybrid_weights['text_analysis']
            quant_weight = self.hybrid_weights['quantitative_analysis']
            
            # ë°ì´í„° í’ˆì§ˆì— ë”°ë¼ ê°€ì¤‘ì¹˜ ì¡°ì •
            if quant_results["data_quality"] == "ì—†ìŒ":
                text_weight = 0.8
                quant_weight = 0.2
            elif quant_results["data_quality"] == "ë‚®ìŒ":
                text_weight = 0.7
                quant_weight = 0.3
            
            hybrid_score = (text_overall["overall_score"] * text_weight + 
                           quant_results["quantitative_score"] * quant_weight)
            hybrid_confidence = (text_overall.get("confidence", 70) * text_weight + 
                               quant_results["confidence"] * quant_weight)
        
        # í•˜ì´ë¸Œë¦¬ë“œ ë“±ê¸‰ ê³„ì‚°
        hybrid_grade_info = self._calculate_hybrid_grade(hybrid_score)
        
        # ê²°ê³¼ ìƒì„±
        result = {
            "uid": uid,
            "overall_score": round(hybrid_score, 1),
            "grade": hybrid_grade_info["grade"],
            "grade_description": hybrid_grade_info["grade_description"],
            "percentile": hybrid_grade_info["percentile"],
            "text_score": text_overall["overall_score"],
            "quantitative_score": quant_results["quantitative_score"],
            "confidence": round(hybrid_confidence, 1),
            "analysis_mode": analysis_mode,
            "timestamp": datetime.now().isoformat()
        }
        
        # 8ëŒ€ ì˜ì—­ë³„ ì ìˆ˜ ì¶”ê°€
        for dimension, score in dimension_scores.items():
            result[f"{dimension}_score"] = score
        
        # AI í”¼ë“œë°± (í•„ìš”ì‹œ ì¶”ê°€)
        if enable_ai and api_key:
            # ì—¬ê¸°ì— OpenAI API í˜¸ì¶œ ë¡œì§ ì¶”ê°€
            result["ai_feedback"] = "AI í”¼ë“œë°± ê¸°ëŠ¥ì€ ì¶”í›„ êµ¬í˜„ ì˜ˆì •ì…ë‹ˆë‹¤."
        
        return result
    
    def _detect_uid_columns(self, df: pd.DataFrame) -> List[str]:
        """UID ì»¬ëŸ¼ ê°ì§€"""
        uid_keywords = ['uid', 'id', 'ì•„ì´ë””', 'ì‚¬ë²ˆ', 'ì§ì›', 'user', 'emp']
        uid_columns = []
        
        for col in df.columns:
            if any(keyword in col.lower() for keyword in uid_keywords):
                uid_columns.append(col)
        
        return uid_columns
    
    def _detect_opinion_columns(self, df: pd.DataFrame) -> List[str]:
        """ì˜ê²¬ ì»¬ëŸ¼ ê°ì§€"""
        opinion_keywords = ['ì˜ê²¬', 'opinion', 'í‰ê°€', 'feedback', 'ë‚´ìš©', 'ì½”ë©˜íŠ¸', 'í”¼ë“œë°±', 'comment', 'review']
        opinion_columns = []
        
        for col in df.columns:
            if any(keyword in col.lower() for keyword in opinion_keywords):
                opinion_columns.append(col)
        
        return opinion_columns
    
    def _calculate_hybrid_grade(self, score: float) -> Dict[str, str]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ë¥¼ OKë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
        if score >= 95:
            return {
                "grade": "OKâ˜…â˜…â˜…",
                "grade_description": "ìµœìš°ìˆ˜ ë“±ê¸‰ (TOP 1%)",
                "percentile": "ìƒìœ„ 1%"
            }
        elif score >= 90:
            return {
                "grade": "OKâ˜…â˜…",
                "grade_description": "ìš°ìˆ˜ ë“±ê¸‰ (TOP 5%)",
                "percentile": "ìƒìœ„ 5%"
            }
        elif score >= 85:
            return {
                "grade": "OKâ˜…",
                "grade_description": "ìš°ìˆ˜+ ë“±ê¸‰ (TOP 10%)",
                "percentile": "ìƒìœ„ 10%"
            }
        elif score >= 80:
            return {
                "grade": "OK A",
                "grade_description": "ì–‘í˜¸ ë“±ê¸‰ (TOP 20%)",
                "percentile": "ìƒìœ„ 20%"
            }
        elif score >= 75:
            return {
                "grade": "OK B+",
                "grade_description": "ì–‘í˜¸- ë“±ê¸‰ (TOP 30%)",
                "percentile": "ìƒìœ„ 30%"
            }
        elif score >= 70:
            return {
                "grade": "OK B",
                "grade_description": "ë³´í†µ ë“±ê¸‰ (TOP 40%)",
                "percentile": "ìƒìœ„ 40%"
            }
        elif score >= 60:
            return {
                "grade": "OK C",
                "grade_description": "ê°œì„ í•„ìš” ë“±ê¸‰ (TOP 60%)",
                "percentile": "ìƒìœ„ 60%"
            }
        else:
            return {
                "grade": "OK D",
                "grade_description": "ì§‘ì¤‘ê°œì„  ë“±ê¸‰ (í•˜ìœ„ 40%)",
                "percentile": "í•˜ìœ„ 40%"
            }