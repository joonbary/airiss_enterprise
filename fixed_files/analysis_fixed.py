# app/api/analysis.py
# AIRISS v4.0 Analysis API - ë¬´í•œ ë¡œë”© í•´ê²° ë²„ì „ (ìˆ˜ì •ë¨)

from fastapi import APIRouter, HTTPException, BackgroundTasks, Depends
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
import uuid
import asyncio
import logging
import traceback
from datetime import datetime
import pandas as pd
import numpy as np
import json

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ë¼ìš°í„° ìƒì„±
router = APIRouter(prefix="/analysis", tags=["analysis"])

# ğŸ”¥ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ì €ì¥ìš©
_db_service = None
_ws_manager = None

def get_db_service():
    """DB ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    global _db_service
    if _db_service is None:
        from app.db.sqlite_service import SQLiteService
        _db_service = SQLiteService()
        logger.info("âœ… SQLiteService ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ë¨")
    return _db_service

def get_ws_manager():
    """WebSocket ë§¤ë‹ˆì € ê°€ì ¸ì˜¤ê¸°"""
    global _ws_manager
    if _ws_manager is None:
        from app.core.websocket_manager import ConnectionManager
        _ws_manager = ConnectionManager()
        logger.info("âœ… WebSocket ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ë¨")
    return _ws_manager

# ğŸ”¥ ì´ˆê¸°í™” í•¨ìˆ˜ (main.pyì—ì„œ í˜¸ì¶œ)
def init_services(db_service, ws_manager):
    """ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”"""
    global _db_service, _ws_manager
    _db_service = db_service
    _ws_manager = ws_manager
    logger.info("âœ… Analysis ëª¨ë“ˆ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")

# [ê¸°ì¡´ AIRISS_FRAMEWORK ì½”ë“œëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€]
# ... (AIRISS_FRAMEWORK, QuantitativeAnalyzer, AIRISSTextAnalyzer, AIRISSHybridAnalyzer ë“±ì€ ë™ì¼)

# API ëª¨ë¸ ì •ì˜
class AnalysisRequest(BaseModel):
    file_id: str
    sample_size: int = 10
    analysis_mode: str = "hybrid"  # "text", "quantitative", "hybrid"
    openai_api_key: Optional[str] = None
    enable_ai_feedback: bool = False
    openai_model: str = "gpt-3.5-turbo"
    max_tokens: int = 1200

# ğŸ”¥ ìˆ˜ì •ëœ ë¶„ì„ ì‹œì‘ ì—”ë“œí¬ì¸íŠ¸
@router.post("/start")
async def start_analysis(
    request: AnalysisRequest, 
    background_tasks: BackgroundTasks
):
    """ë¶„ì„ ì‘ì—… ì‹œì‘ - ë¬´í•œ ë¡œë”© í•´ê²° ë²„ì „"""
    try:
        logger.info(f"ğŸš€ ë¶„ì„ ì‹œì‘ ìš”ì²­: file_id={request.file_id}, sample_size={request.sample_size}")
        
        # DB ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        db_service = get_db_service()
        ws_manager = get_ws_manager()
        
        # DB ì´ˆê¸°í™” í™•ì¸
        try:
            await db_service.init_database()
        except Exception as e:
            logger.warning(f"DB ì´ˆê¸°í™” ê±´ë„ˆëœ€: {e}")
        
        # 1. íŒŒì¼ ì¡´ì¬ í™•ì¸
        file_data = await db_service.get_file(request.file_id)
        if not file_data:
            logger.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {request.file_id}")
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # 2. ì‘ì—… ID ìƒì„±
        job_id = str(uuid.uuid4())
        logger.info(f"ğŸ†• ì‘ì—… ID ìƒì„±: {job_id}")
        
        # 3. ì‘ì—… ë°ì´í„° ì¤€ë¹„
        job_data = {
            "job_id": job_id,
            "file_id": request.file_id,
            "status": "processing",
            "sample_size": request.sample_size,
            "analysis_mode": request.analysis_mode,
            "enable_ai_feedback": request.enable_ai_feedback,
            "openai_model": request.openai_model,
            "max_tokens": request.max_tokens,
            "start_time": datetime.now().isoformat(),
            "progress": 0.0,
            "total_records": request.sample_size,
            "processed_records": 0,
            "failed_records": 0,
            "version": "4.0"
        }
        
        # 4. SQLiteì— ì‘ì—… ì €ì¥
        saved_job_id = await db_service.create_analysis_job(job_data)
        if saved_job_id != job_id:
            logger.error(f"âŒ Job ID ë¶ˆì¼ì¹˜! ìš”ì²­: {job_id}, ì €ì¥: {saved_job_id}")
            raise HTTPException(status_code=500, detail="ì‘ì—… ID ìƒì„± ì˜¤ë¥˜")
        
        # 5. ğŸ”¥ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì¶”ê°€ (FastAPI BackgroundTasks ì‚¬ìš©)
        background_tasks.add_task(
            safe_process_analysis_v4,
            job_id,
            request,
            db_service,
            ws_manager
        )
        logger.info(f"âœ… ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì¶”ê°€ ì™„ë£Œ: {job_id}")
        
        # 6. WebSocket ì•Œë¦¼
        try:
            await ws_manager.broadcast_to_channel("analysis", {
                "type": "analysis_started",
                "job_id": job_id,
                "file_id": request.file_id,
                "analysis_mode": request.analysis_mode,
                "timestamp": datetime.now().isoformat()
            })
        except Exception as e:
            logger.warning(f"âš ï¸ WebSocket ì•Œë¦¼ ì‹¤íŒ¨: {e}")
        
        # 7. ì„±ê³µ ì‘ë‹µ
        return {
            "job_id": job_id,
            "status": "started",
            "message": "OKê¸ˆìœµê·¸ë£¹ AIRISS v4.0 í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤",
            "ai_feedback_enabled": request.enable_ai_feedback,
            "analysis_mode": request.analysis_mode,
            "sample_size": request.sample_size,
            "estimated_time": f"{request.sample_size * 0.2}ì´ˆ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ë¶„ì„ ì‹œì‘ ì˜¤ë¥˜: {e}")
        logger.error(f"ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì‹œì‘ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")

# ğŸ”¥ ìˆ˜ì •ëœ ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ í•¨ìˆ˜
async def safe_process_analysis_v4(job_id: str, request: AnalysisRequest, db_service, ws_manager):
    """ì•ˆì „í•œ ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ì²˜ë¦¬"""
    try:
        logger.info(f"ğŸ”¥ ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ì‹œì‘: {job_id}")
        
        # ì‹¤ì œ ë¶„ì„ ì²˜ë¦¬
        await process_analysis_v4(job_id, request, db_service, ws_manager)
        
        logger.info(f"âœ… ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ì™„ë£Œ: {job_id}")
        
    except Exception as e:
        logger.error(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ì˜¤ë¥˜: {job_id} - {e}")
        logger.error(f"ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
        
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸
        try:
            await db_service.update_analysis_job(job_id, {
                "status": "failed",
                "error": f"ë¶„ì„ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
                "end_time": datetime.now().isoformat()
            })
            
            # WebSocket ì˜¤ë¥˜ ì•Œë¦¼
            await ws_manager.broadcast_to_channel("analysis", {
                "type": "analysis_failed",
                "job_id": job_id,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            })
            
        except Exception as update_error:
            logger.error(f"âŒ ì˜¤ë¥˜ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {update_error}")

# ğŸ”¥ ê°„ì†Œí™”ëœ ë¶„ì„ ì²˜ë¦¬ í•¨ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)
async def process_analysis_v4(job_id: str, request: AnalysisRequest, db_service, ws_manager):
    """AIRISS v4.0 ë¶„ì„ ì²˜ë¦¬ - ê°„ì†Œí™” ë²„ì „"""
    try:
        logger.info(f"ğŸ“Š ë¶„ì„ ì²˜ë¦¬ ì‹œì‘: {job_id}")
        
        # 1. íŒŒì¼ ë°ì´í„° ë¡œë“œ
        file_data = await db_service.get_file(request.file_id)
        if not file_data:
            raise Exception(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {request.file_id}")
        
        # 2. DataFrame í™•ì¸
        df = file_data.get('dataframe')
        if df is None:
            raise Exception("DataFrameì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        logger.info(f"ğŸ“‹ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}í–‰")
        
        # 3. ìƒ˜í”Œ ë°ì´í„° ì„ íƒ
        sample_size = min(request.sample_size, len(df))
        sample_df = df.head(sample_size).copy()
        
        # 4. ì»¬ëŸ¼ ì •ë³´ í™•ì¸
        uid_cols = file_data.get("uid_columns", [])
        opinion_cols = file_data.get("opinion_columns", [])
        
        if not uid_cols:
            # UID ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì»¬ëŸ¼ ì‚¬ìš©
            uid_cols = [df.columns[0]]
        
        # 5. ê°„ë‹¨í•œ ë¶„ì„ ì§„í–‰ (í…ŒìŠ¤íŠ¸ìš©)
        results = []
        total_rows = len(sample_df)
        
        for idx, row in sample_df.iterrows():
            try:
                # UID ì¶”ì¶œ
                uid = str(row[uid_cols[0]]) if uid_cols else f"user_{idx}"
                
                # ì„ì‹œ ì ìˆ˜ ìƒì„± (60-90 ë²”ìœ„)
                main_score = 60 + (idx % 30)
                
                # ë“±ê¸‰ ê³„ì‚°
                if main_score >= 90:
                    main_grade = "OKâ˜…â˜…â˜…"
                elif main_score >= 85:
                    main_grade = "OKâ˜…â˜…"
                elif main_score >= 80:
                    main_grade = "OKâ˜…"
                elif main_score >= 75:
                    main_grade = "OK A"
                elif main_score >= 70:
                    main_grade = "OK B+"
                else:
                    main_grade = "OK B"
                
                # ê²°ê³¼ ë ˆì½”ë“œ ìƒì„±
                result_record = {
                    "UID": uid,
                    "ì›ë³¸ì˜ê²¬": "í…ŒìŠ¤íŠ¸ ë¶„ì„ ì¤‘...",
                    "AIRISS_v4_ì¢…í•©ì ìˆ˜": main_score,
                    "OKë“±ê¸‰": main_grade,
                    "ë“±ê¸‰ì„¤ëª…": f"{main_grade} ë“±ê¸‰",
                    "ë°±ë¶„ìœ„": f"ìƒìœ„ {100 - idx}%",
                    "ë¶„ì„ì‹ ë¢°ë„": 80.0,
                    "ë¶„ì„ëª¨ë“œ": request.analysis_mode,
                    "ë¶„ì„ì‹œê°„": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                }
                
                # SQLiteì— ê°œë³„ ê²°ê³¼ ì €ì¥
                await db_service.save_analysis_result(job_id, uid, result_record)
                results.append(result_record)
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                current_processed = len(results)
                progress = (current_processed / total_rows) * 100
                
                await db_service.update_analysis_job(job_id, {
                    "processed_records": current_processed,
                    "progress": min(progress, 100)
                })
                
                # WebSocket ì§„í–‰ë¥  ì•Œë¦¼
                await ws_manager.broadcast_to_channel("analysis", {
                    "type": "analysis_progress",
                    "job_id": job_id,
                    "progress": progress,
                    "processed": current_processed,
                    "total": total_rows,
                    "current_uid": uid,
                    "current_score": main_score,
                    "timestamp": datetime.now().isoformat()
                })
                
                logger.info(f"ğŸ“ˆ ì§„í–‰ë¥ : {progress:.1f}% ({current_processed}/{total_rows})")
                
                # ì²˜ë¦¬ ì†ë„ ì¡°ì ˆ
                await asyncio.sleep(0.1)  # 0.1ì´ˆ ëŒ€ê¸°
                
            except Exception as e:
                logger.error(f"âŒ ê°œë³„ ë¶„ì„ ì˜¤ë¥˜ - UID {idx}: {e}")
                continue
        
        # 6. ë¶„ì„ ì™„ë£Œ ì²˜ë¦¬
        end_time = datetime.now()
        avg_score = sum(r["AIRISS_v4_ì¢…í•©ì ìˆ˜"] for r in results) / len(results) if results else 0
        
        await db_service.update_analysis_job(job_id, {
            "status": "completed",
            "end_time": end_time.isoformat(),
            "average_score": round(avg_score, 1),
            "processed_records": len(results),
            "progress": 100.0
        })
        
        # WebSocket ì™„ë£Œ ì•Œë¦¼
        await ws_manager.broadcast_to_channel("analysis", {
            "type": "analysis_completed",
            "job_id": job_id,
            "total_processed": len(results),
            "average_score": round(avg_score, 1),
            "timestamp": end_time.isoformat()
        })
        
        logger.info(f"ğŸ‰ ë¶„ì„ ì™„ë£Œ: {job_id}, ì²˜ë¦¬: {len(results)}ê±´")
        
    except Exception as e:
        logger.error(f"âŒ ë¶„ì„ ì²˜ë¦¬ ì˜¤ë¥˜: {job_id} - {e}")
        logger.error(f"ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
        
        # ì‹¤íŒ¨ ìƒíƒœ ì—…ë°ì´íŠ¸
        await db_service.update_analysis_job(job_id, {
            "status": "failed",
            "error": str(e),
            "end_time": datetime.now().isoformat()
        })
        
        # WebSocket ì˜¤ë¥˜ ì•Œë¦¼
        await ws_manager.broadcast_to_channel("analysis", {
            "type": "analysis_failed",
            "job_id": job_id,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        })
        
        raise

# [ê¸°ì¡´ì˜ ë‚˜ë¨¸ì§€ ì—”ë“œí¬ì¸íŠ¸ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€]
# @router.get("/status/{job_id}")
# @router.get("/jobs")
# @router.get("/results/{job_id}")
# @router.get("/download/{job_id}/{format}")
# @router.get("/health")
# ... (ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ)
